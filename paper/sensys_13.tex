\documentclass[10pt]{sensys-proc}

%\usepackage{afterpage}
\usepackage{balance}
\usepackage{verbatim}
\usepackage{xspace}
%\usepackage{amssymb}
%\usepackage{amsmath}
%\usepackage{fancyvrb}
%\usepackage{booktabs}
%\usepackage{colortbl}
%\usepackage{tabularx}
%\usepackage{multirow}
%\usepackage{color}
%\usepackage{hyperref}    % Creates hyperlinks from ref/cite 
%\hypersetup{pdfstartview=FitH}
\usepackage{graphicx}
\usepackage{url}

%\renewcommand{\arraystretch}{1.2} % Space out rows in tables

\setlength\paperheight {11in}
\setlength\paperwidth {8.5in}

% No space between bibliography items:
\let\oldthebibliography=\thebibliography
  \let\endoldthebibliography=\endthebibliography
  \renewenvironment{thebibliography}[1]{%
    \begin{oldthebibliography}{#1}%
      \setlength{\parskip}{0ex}%
      \setlength{\itemsep}{0ex}%
  }%
  {%
    \end{oldthebibliography}%
  }
\setlength{\parindent}{5mm}

\newcommand{\compresslist}{
	\setlength{\itemsep}{1pt}
	\setlength{\parskip}{0pt}
	\setlength{\parsep}{0pt}
}

\newenvironment{itemize*}%
  {\begin{itemize}%
    \setlength{\itemsep}{0pt}%
    \setlength{\parskip}{0pt}}%
  {\end{itemize}}
\usepackage{enumitem}
\setlist{nolistsep}

%\relpenalty=9999
%\binoppenalty=9999

\newcommand{\CEU}{\textsc{C\'{e}u}\xspace}
\newcommand{\code}[1] {{\small{\texttt{#1}}}}
\newcommand{\Code}[1] {\texttt{#1}}

\begin{comment}
\numberofauthors{2}

\author{
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
%% e-mail address with \email.
\alignauthor Alice Security \\
        \affaddr{Department of Computer Science}\\
        \affaddr{University of Southern California}\\
       \email{alice@example.edu}
\alignauthor Bob Privacy \\
    \affaddr{Networked Embedded Systems Group}\\
    \affaddr{Swedish Institute of Computer Science}\\
    \email{bob@example.se}
}
%\author{
    %{Francisco Sant'Anna} \\
    %\affaddr{Departamento de Inform\'atica - PUC-Rio} \\
    %\email{fsantanna@inf.puc-rio.br}
%}
\end{comment}

%\title{Safe Concurrent Abstractions for Wireless Sensor Networks}
\title{Safe Synchronous Abstractions for Wireless Sensor Networks}

%\crdata{978-1-4503-1169-4}
%\conferenceinfo{SenSys'13,} {November X--X, 2013, Rome, Italy.}
%\CopyrightYear{2013}

\begin{document}

\maketitle

\begin{abstract}
ABSTRACT
% EOD -> MT -> SYN/HIER
\end{abstract}

% A category with the (minimum) three required fields
%\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, 
%performance measures]

%\terms{Delphi theory}

%\keywords{ACM proceedings, \LaTeX, text tagging}

\section{Introduction}
\label{sec.intro}

\begin{comment}
TODO
Wireless sensor networks (WSNs) are composed of a large number of tiny devices 
(known as ``motes'') capable of sensing the environment and communicating among 
them.
WSNs are usually employed to continuously monitor physical phenomena in large 
or unreachable areas, such as wildfire in forests and air temperature in 
buildings.
Each mote features limited processing capabilities, a short-range radio link, 
and one or more sensors (e.g. light and temperature) \cite{wsn.survey}.
\end{comment}

Applications developed for wireless sensor networks (WSNs) typically perform a 
succession of sensing, processing, actuating, and communicating.
This process involves an external environment, which concurrently interacts 
with the application by issuing events that represent expiring timers, messages 
arrivals, sensor readings, etc.
%The fact that the application is not in charge of the environment results in a 
%high degree of concurrency among events occurrences and the program execution.

% TODO: system/node

The first languages and operating systems for WSNs provide an event-driven 
programming model \cite{wsn.tos,wsn.contiki}, in which each external event can
be associated with a short-lived function callback to handle a reaction to the 
environment.
This model is efficient for the severe resource constraints of WSNs, but is 
difficult to program, given the ineffectiveness of local 
variables~\cite{sync_async.cooperative} and the explicit management of state 
machines~\cite{wsn.protothreads}.

Multi-threaded systems emerged as an alternative, providing traditional 
structured programming for WSNs (e.g.~\cite{wsn.protothreads,wsn.mantisos}).
However, the programmer still has to manually synchronize and maintain threads 
(e.g. create, start, and destroy).
Furthermore, preemptive scheduling of threads is a potential source of safety 
hazards~\cite{sync_async.threadsproblems}, while cooperative scheduling is 
susceptible to unbounded execution (i.e. infinite loops), breaking 
responsiveness in programs~\cite{wsn.comparison}.

Synchronous languages are a higher-level alternative that have been 
successfully adapted to WSNs without imposing a significant 
overhead~\cite{wsn.sol,wsn.osm}.
%We believe that the programming facilities found in these languages match 
%perfectly with the reactive nature of WSNs and can be adopted in this context.
They provide high-level compositions of concurrent activities through 
hierarchies of processes~\cite{esterel.ieee91} or state 
machines~\cite{statecharts.visual}, reducing the programmer efforts with 
synchronization issues.

However, existing synchronous languages targetting WSNs do not consider safety 
aspects in a broad view, suffering from the same difficulties of multi-threaded 
designs.
For instance, shared memory is usually the only mechanism for communication and 
synchronization, but current works do not go beyond atomic access guarantees 
relying on a run to completion semantics~\cite{wsn.sol,wsn.osm}.

Furthermore, WSN development typically involves low-level access to the 
platform through $C$ system calls that pass pointers back and forth (e.g.  
message buffers to the radio driver).
Current works do not discuss effective policies to handle such corner cases.
For instance, the claimed gains in memory and expressiveness with support for 
locals~\cite{wsn.ocram,wsn.osm} are under safety threats if pointers that go 
out of scope are used.

In this work, we present the design of \CEU%
\footnote{C\'eu is the Portuguese word for \emph{sky}.}, a system-level 
programming language based on Esterel~\cite{esterel.ieee91} that provides a 
reliable yet powerful programming environment for WSNs.
We explore the precious control information that can be inferred from 
compositions at compile time in order to embrace safety aspects to a greater 
extend.

Our design is first compromised with the main principles that govern WSNs 
development: \emph{resource minimization} and \emph{bug prevention}, as defined 
by Levis~\cite{wsn.decade}.
That said, support for hierarchical compositions, together with a convenient 
syntax for timers and internal communication also lead to more compact programs 
(up to 70\% reduction, in our evaluation).

Currently, our design focus only on \emph{concurrency safety}, rather than on 
\emph{type safety}~\cite{wsn.safety}.
We consider both aspects to be complimentary and orthogonal, i.e., type safety 
annotations and runtime checks could also be applied to \CEU.

\begin{comment}
TODO
\CEU is based on Esterel~\cite{esterel.ieee91} and follows a synchronous 
execution model~\cite{rp.twelve}, which enforces a disciplined step-by-step 
execution.
\CEU relies on a compile-time analysis to detect unbounded loops and concurrent 
access to variables.
\end{comment}

Our overall contribution is the careful design of concurrent abstractions that 
considers safety aspects for every proposed functionality.
As more specific contributions, we enumerate the following language features:

\begin{figure*}[!t]
%\rule{8.5cm}{0.37pt}
\begin{minipage}[t]{0.24\linewidth}
{\small
\begin{verbatim}
/*********** NESC ***********/
event void Boot.booted () {
  call T1.startOneShot(0);
  call T2.startOneShot(60000);
}
event void T1.fired () {
  static int on = 0;
  if (on) {
    call Leds.led0Off();
    call T1.startOneShot(2000);
  } else {
    call Leds.led0On();
    call T1.startOneShot(1000);
  }
  on = !on;
}
event void T2.fired () {
  call T1.cancel();
  call Leds.led0Off();
  <...> // CONTINUE
}
\end{verbatim}
}
\end{minipage}
%
\hfill \vrule \hfill
\hspace{0.0cm}
%
\begin{minipage}[t]{0.28\linewidth}
%\fbox{
{\small
\begin{verbatim}
/********* PROTOTHREADS *********/
int main () {
  timer_set(&timeout, 60000);
  PT_INIT(&blink);
  while (
    PT_SCHEDULE(blink()) &&
    !timer_expired(timeout)
  );
  leds_off(LEDS_RED);
  <...> // CONTINUE
}
PT_THREAD blink () {
  while (1) {
    leds_on(LEDS_RED);
    timer_set(&timer, 2000);
    PT_WAIT_UNTIL(expired(&timer));
    leds_off(LEDS_RED);
    timer_set(&timer, 1000);
    PT_WAIT_UNTIL(expired(&timer));
  }
}
\end{verbatim}
%}
}
\end{minipage}
%
\hfill \vrule \hfill
\hspace{0.0cm}
%
\begin{minipage}[t]{0.18\linewidth}
%\fbox{
{\small
\begin{verbatim}
/******** CEU ********/
par/or do
   loop do
      _Leds_led0On();
      await 2s;
      _Leds_led0Off();
      await 1s;
   end
with
   await 1min;
end
_Leds_led0Off(0);
<...> // CONTINUE
\end{verbatim}
%}
}
\end{minipage}
%
\hfill \vrule \hfill
\hspace{0.0cm}
%
\begin{minipage}[t]{0.15\linewidth}
\vspace{0pt}
\centering
\includegraphics[scale=0.45]{dia.png}
\end{minipage}
%
\hspace{0.0cm}
%
\rule{18cm}{0.37pt}
\caption{ ``Blinking LED'' in
    nesC~\cite{wsn.nesc},
    Protothreads~\cite{wsn.protothreads},
    and \CEU.
    (TODO: point (1..4) in the impls.)
\label{lst.all}
}
\end{figure*}

\begin{itemize}
\item A compile-time analysis that enforces reliable shared-memory concurrency.
\item A finalization mechanism to safely release resources just before they go 
      out of scope.
\item First-class timers with a predictable behavior.
\item A stack-based inter-thread communication mechanism that provides a 
      restricted (but safer) form of subroutines.
      % and can be used to handle exceptions.
\item An object system that provides code reentrancy and enables the creation 
      of higher-level abstractions.
\end{itemize}

As a limitation of the synchronous model, computations that run in unbounded 
time (e.g., cryptography, image processing) do not fit the zero-delay reaction
hypothesis~\cite{rp.hypothesis}, and cannot be elegantly implemented in \CEU.
Also, the static analysis precludes any dynamic support in the language, such 
as memory allocation and dynamic loading.
However, this trade-off seems to be favorable in the context of WSNs, as 
dynamic features are discouraged due to resource constraints and safety 
requirements.

\begin{comment}
TODO

SAFETY, both react to time, what if they access memory, who executes first
CEU detects at compile time and raises a warning

Node-system-imperative
    - not macro
    - not declarative
    - drivers, protocols, control-intensive apps

Synchronous
    - not preemptive, actors

ED->MT->HC

Safety and expressiveness co-design

abstractions need to be first class
\end{comment}

The rest of the paper is organized as follows:
Section~\ref{sec.overview} gives an overview of how different programming 
models used in WSNs can express typical control patterns.
Section~\ref{sec.ceu} details the design of \CEU by motivating, describing, 
exemplifying, and discussing safety aspects of each relevant language feature.
In Section~\ref{sec.eval}, we describe how we ported to \CEU the open-source 
implementations of some open standards~\cite{wsn.teps} (e.g. network protocols 
and a radio driver),
% (the \emph{CC2420} radio driver, the \emph{trickle} timer, and the 
%\emph{DRIP}, \emph{SRP}, and \emph{CTP} protocols)
comparing some quantitative aspects with \emph{nesC} (e.g. memory usage and 
tokens count) backed by a thoughtful discussion.
Section~\ref{sec.related} presents a XXX of related works to \CEU.
Section~\ref{sec.conclusion} concludes the paper and makes final remarks.

\section{Overview of programming models}
\label{sec.overview}

As briefly introduced, WSNs applications must handle a multitude of concurrent 
events, such as from timers and packet transmissions.
Although they may seem random and unrelated for an external observer, the 
programmer keeps track of them in a logical fashion, according to the 
application specification.

From a control perspective, the logical relations among events represent 
activities in an application and follow two main patterns: \emph{sequential}, 
i.e., activities composed of two or more states in sequence; or 
\emph{parallel}, i.e., unrelated activities that eventually need to 
synchronize.

As an example, an application that alternates between sampling a sensor and 
broadcasting its readings has a clear sequential pattern (with an enclosing 
loop); while including an 1-minute timeout to interrupt the activity comprises 
a parallel pattern.

An effective language for WSNs should provide control abstractions that better 
express the programmer intentions, desirably ensuring that the high degree of 
concurrency does not impose safety threats.

Figure~\ref{lst.all} exposes the different programming models used in WSNs, 
showing three implementations for an application that continuously lights on a 
LED for 2 seconds and off for 1 second.
After 1 minute, the application turns off the LED and proceeds to the code 
marked as \code{<...>}.
The diagram on the right describes the control behavior for the application.
The sequential pattern is represented with the LED alternating between the two 
states, while the parallel pattern is represented by the 1-minute timeout.
% that interrupts the blinking LED.

The first implementation, which represents the \emph{event-driven} 
model~\cite{wsn.nesc,wsn.contiki}, spawns two timers at boot time 
(\code{Boot.booted}), one to blink the LED and another to wait for 1 minute.
The callback \code{T1.fired} continuously toggles the LED and resets the timer 
according to the state variable \code{on}.
The callback \code{T2.fired} executes once, cancelling the blinking timer and 
proceeding to \code{<...>}.
This implementation is the least structured, given that the blinking loop is 
not explicit, but instead, relies on a static state variable and multiple 
invocations of the same callback.
Furthermore, the timeout handler needs specific knowledge on how to stop the 
blinking activity manually (\code{T1.cancel()}).

The second implementation, which represents the \emph{multi-threaded} 
model~\cite{wsn.protothreads,wsn.mantisos}, uses a dedicated thread to blink 
the LED in a loop, bringing more structure to the solution.
The main thread also helps identifying the overall sequence of the program, 
which is not easily identifiable in the event-driven implementation without 
tracking the dependencies among callbacks.
However, it still requires a lot of bookkeeping for initializing, scheduling 
and rejoining the blinking thread after the timeout.

% ASYNC MT?

The third implementation, in \CEU, which represents the \emph{synchronous 
model}~\cite{wsn.osm,wsn.sol}, uses a \code{par/or} construct to run the two 
activities in parallel:
an endless loop to blink the LED, and a single statement that waits for 1 
minute before terminating.
A \code{par/or} stands for \emph{parallel or} and rejoins automatically when 
any of its trails terminates.
(\CEU also supports \code{par/and} compositions, which rejoin when \emph{all} 
spawned trails terminate.)

The hierarchical syntactic structure more closely reflects the diagram and ties 
the two activities together, implying that
(a) they can only exist together;
(b) they always start together
(c) they always terminate together.

Besides the arguably cleaner syntax, the additional control-flow information 
provided in the program is the base for all features and safety guarantees 
introduced by \CEU.

% TODO
%The challenge is how to provide a design that embraces/xxx safety/determinism, 
%specially considering pointers

%\afterpage{clearpage}
\section{The design of C\'eu}
\label{sec.ceu}

\CEU{} is a concurrent language in which multiple lines of execution (known as 
\emph{trails}) continuously react to input events from the environment.
Waiting for an event halts the running trail until that event occurs.
The environment broadcasts occurring events to all active trails, which share a 
single global time reference (an event itself).

%\subsection{Parallel syntactic compositions}
%\label{sec.ceu.par}

The fundamental distinction between \CEU and prevailing multi-threaded designs 
is the way threads are combined in programs.
\CEU provides Esterel-like syntactic hierarchical compositions, while 
conventional multi-threaded systems typically only support top-level 
definitions for threads.

The example in Figure~\ref{lst.radio} is extracted from our port of the 
\emph{CC2420} radio driver~\cite{wsn.teps} to \CEU and uses a \code{par/or} to 
control the start/stop behavior of the radio.
The input events \code{CC2420\_START} and \code{CC2420\_STOP} represent the 
external interface of the driver with a client application (e.g. a protocol).
The driver enters the top-level loop and awaits the starting event;
upon request, the driver spawns two other trails:
one that awaits the stopping event,
and another to actually receive radio messages in a loop.

\begin{figure}[t]
%\rule{8.5cm}{0.37pt}
{\small
\begin{verbatim}
    input void CC2420_START, CC2420_STOP;
    loop do
        await CC2420_START;
        par/or do
            await CC2420_STOP;
        with
            // loop with other nested trails
            // to receive radio packets
            <...>
        end
    end
\end{verbatim}
}%
\rule{8.5cm}{0.37pt}
\caption{ Start/stop behavior for the radio driver.
\label{lst.radio}
}
\end{figure}

As compositions can be nested, the receive loop can be as complex as needed, 
but once an external request to stop the driver is triggered, the \code{par/or} 
composition kills all nested trails and proceeds to the statement in sequence.
In this case, the top-level loop restarts, waiting again for the start event.

The \code{par/or} construct is regarded as an \emph{orthogonal preemption 
primitive}~\cite{esterel.preemption} because the two sides in the composition 
do not know when and why they get killed.
Furthermore, they need not to be tweaked with synchronization primitives or 
state variables in order to be affected by related trails in parallel.

\begin{comment}
The same start/stop control pattern for the radio driver appears in all ported 
network protocols presented in Section~\ref{sec.eval}.
In practical terms, parallel compositions eliminated all state variables in our 
ports, not only those related to split-phase 
operations~\cite{wsn.protothreads}.
\end{comment}

\subsection{Deterministic and bounded execution}
\label{sec.ceu.det}

% TODO: motivate?

\CEU{} is grounded on a precise definition of time as a discrete sequence of 
external input events:
% \footnote{We use the terms \emph{external input event}, \emph{external event}, 
%and \emph{input event} interchangeably.}
a sequence because only a single input event is handled at a time; discrete 
because a complete reaction always executes in bounded time (to be discussed 
further).
The execution model for a \CEU{} program is as follows:

\begin{enumerate}
\item The program initiates the ``boot reaction'' in a single trail.
\item Active trails execute until they await or terminate.
      This step is named a \emph{reaction chain}, and always runs in bounded 
      time.
\item The program goes idle and the environment takes control.
\item On the occurrence of a new external input event, the environment awakes 
      \emph{all} trails awaiting that event.
      It then goes to step 2.
\end{enumerate}

% TODO
The synchronous model is based on the hypothesis that internal reactions run 
\emph{infinitely faster} than the rate of events from the 
environment~\cite{rp.hypothesis}.
Conceptually, a program takes no time on step 2 and is always idle on step 3.
In practice, if a new external input event occurs while a reaction chain is 
running (step 2), it is enqueued to run in the next reaction.
%, because reaction chains must run to completion.

% TODO: a similar approach is taken in \cite{...}

When multiple trails are active at a time (i.e. awaking from the same event), 
\CEU schedules them in the order they appear in the program text.
This policy is somewhat arbitrary, but provides a priority scheme for trails, 
and also ensures a deterministic and reproducible execution for programs.

The blinking LED example of Figure~\ref{lst.all} illustrates how the 
synchronous model leads to a simpler reasoning about concurrency aspects.
As reaction times are assumed to be instantaneous, the blinking loop takes 
exactly 3 seconds.
Hence, after 20 iterations, the accumulated time becomes 1 minute and the loop 
terminates concurrently with the 1-minute timeout in parallel.
Given that the blinking trail is defined first, the loop restarts and turns on 
the LED for the last time.
Then, the blinking trail awaits again, and the 1-minute timeout is scheduled 
and kills the whole \code{par/or}.
This reasoning is reproducible in practice, and the LED will light on exactly 
21 times for every execution of this program.
First-class timers are discussed in more depth in Section~\ref{sec.ceu.time}.

The described behavior is known as \emph{weak abortion}, because the blinking 
trail has the chance to execute for the last time.
By inverting the two trails, the \code{par/or} terminates immediately, and the 
blinking trail does not execute, qualifying a \emph{strong 
abortion}.~\cite{esterel.preemption}

\CEU not only provides means to choose between weak and strong abortion, but 
also detects the two possibilities and issues a warning at compile time (to be 
discussed in Section~\ref{sec.ceu.shared}).

Reactions to the environment should run in bounded time to guarantee that 
programs are responsive and can handle upcoming input events.
Similarly to Esterel~\cite{esterel.ieee91}, \CEU requires that each possible 
path in a loop body contains at least one \code{await} or \code{break} 
statement, thus ensuring that loops never run in unbounded time.

Consider the examples that follow:

{\small
\begin{verbatim}
    loop do                     loop do
        if <cond> then              if <cond> then
            break;                      break;
        end                         else
    end                                 await A;
                                    end
                                end
\end{verbatim}
}

The first example is refused at compile time, because the \code{if} true branch 
may never execute, resulting in a \emph{tight loop} (i.e., an infinite loop 
that does not await).
The second variation is accepted, because for every iteration, the loop either 
breaks or awaits.

Enforcing bounded execution makes \CEU inappropriate for algorithmic-intensive 
applications that require unrestricted loops (e.g., cryptography, image 
processing).
However, \CEU is designed for control-intensive applications and we believe 
this is a reasonable price to pay in order to achieve higher reliability.

% TODO: pause

\subsection{Shared-memory concurrency}
\label{sec.ceu.shared}

WSNs applications make extensive use of shared memory, such as memory pools, 
message queues, routing tables, etc.
Hence, an important goal of \CEU is to ensure a reliable execution for 
concurrent programs that use shared memory.

Concurrency in \CEU is characterized when two or more trails segments execute 
during the same reaction chain.
A trail segment is a sequence of statements separated by an \code{await}.

In first example that follows, the assignments run concurrently, because both 
trail segments are spawned during the same reaction chain.
However, in the second example, the assignments are never concurrent, because 
$A$ and $B$ represent different external events and the respective segments can 
never execute during the same reaction chain:

\begin{minipage}[t]{0.40\linewidth}
{\small
\begin{verbatim}
var int v=0;
par/and do
    v = v + 1;
with
    v = v * 2;
end
\end{verbatim}
}
\end{minipage}
\hspace{0cm}
\begin{minipage}[t]{0.40\linewidth}
{\small
\begin{verbatim}
input void A, B;
var int v=0;
par/and do
    await A;
    v = v + 1;
with
    await B;
    v = v * 2;
end

\end{verbatim}
}
\end{minipage}

Note that although variable $v$ is accessed concurrently in the first example, 
the assignments are both atomic and deterministic (given the run to completion 
semantics and the scheduling policy): the final value of $v$ is always $2$.

However, programs with concurrent accesses to shared memory are suspicious, 
because an apparently innocuous reordering of trails modifies the semantics of 
the program.

%Moreover, \CEU also supports pointers, which are required for low-level 
%manipulation (e.g., accessing buffers from device drivers).

We developed a compile-time temporal analysis for \CEU in order to detect 
concurrent accesses to shared variables:
If a variable is written in a trail segment, then a concurrent trail segment 
cannot read or write to that variable, nor dereference a pointer of that 
variable type.
An analogous policy is applied for pointers vs variables and pointers vs 
pointers.

For each variable access, the algorithm holds the set of all possible preceding 
\code{await} statements.
Then, the sets for all accesses in parallel trails are compared to assert that 
no \code{await} statements are shared.
Otherwise the compiler warns the programmer about the suspicious accesses.

Consider the three examples of Figure~\ref{lst.det}.
The first code is detected as suspicious, given that both assignments may be 
concurrent in a reaction to $A$ (lines 11 and 14);
In the second code, although two of the assignments occur in reactions to $A$ 
(lines 5 and 11), they are not in parallel trails and, hence, are safe.
The third code illustrates a false positive in our algorithm, as the 
assignments in parallel can only occur in different reactions to $A$ (lines 5 
and 9).

\begin{figure}[t]
\begin{minipage}[t]{0.05\linewidth}
{\small
\begin{verbatim}
 1:
 2:
 3:
 4:
 5:
 6:
 7:
 8:
 9:
10:
11:
12:
13:
14:
15:
\end{verbatim}
}
\end{minipage}
\hspace{0cm}
\begin{minipage}[t]{0.32\linewidth}
{\small
\begin{verbatim}
input void A;
var int v;
var int* p;
par/or do
  loop do
    await A;
    if <cnd> then
      break;
    end
  end
  v = 1;
with
  await A;
  *p = 2;
end
\end{verbatim}
}
\end{minipage}
\hspace{0cm}
\begin{minipage}[t]{0.29\linewidth}
{\small
\begin{verbatim}
input void A, B;
var int v;
par/or do
  await A;
  v = 1;
with
  await B;
  v = 2;
end
await A;
v = 3;
\end{verbatim}
}
\end{minipage}
\hspace{0cm}
\begin{minipage}[t]{0.25\linewidth}
{\small
\begin{verbatim}
input void A;
var int v;
par/and do
  await A;
  v = 1;
with
  await A;
  await A;
  v = 2;
end
\end{verbatim}
}
\end{minipage}
\rule{8.5cm}{0.37pt}
\caption{ The first and third programs are suspicious.
\label{lst.det}
}
\end{figure}

The proposed static analysis is only possible due to syntactic compositions, 
which provide precise information about the flow of trails, i.e., which run in 
parallel and which are guaranteed to be in sequence.

We also implemented an alternative algorithm that converts a \CEU program into 
a deterministic finite automata.
The resulting DFA represents all possible points a program can reach during 
runtime and, hence, eliminates all false positives.
However, the algorithm is exponential and may be impractical in many 
situations.

That said, we run the simpler static analysis for all ports presented in 
Section~\ref{sec.eval} and no false positives were detected, suggesting that 
the algorithm is practical.

Weak and strong abortions, as presented in Section~\ref{sec.ceu.det}, are also 
detected with the proposed algorithm.
Instead of accesses to variables, the algorithm asserts that no join points of 
a \code{par/or} execute concurrently with a trail in parallel, issuing a 
warning otherwise.

% TODO: negligible time

\subsection{Integration with $C$}
\label{sec.ceu.c}

Most existing operating systems, programming languages, and libraries for WSNs 
rely on $C$, given its omnipresence and level of portability across embedded 
platforms.
This way, it is fundamental that programs in \CEU have access to all 
functionality the underlying platform already provides.

In \CEU, any identifier prefixed with an underscore is repassed \emph{as is} to 
the $C$ compiler that generates the final binary.
This way, access to $C$ is seamless and, more importantly, easily trackable.

% TODO: remove

\CEU also supports \emph{C~blocks} to define new symbols, as Figure~\ref{lst.c} 
illustrates.
All code inside ``\code{C do ... end}'' is also repassed to the $C$ compiler 
for the final generation phase.
%Only global definitions are allowed inside $C$ blocks.
Note that \CEU{} mimics the type system of $C$, so that values can be 
seamlessly passed back and forth between the languages.

% TODO: real example?
\begin{figure}[t]
%\rule{8.5cm}{0.37pt}
{\small
\begin{verbatim}
   C do
       #include <assert.h>
       int I = 0;
       int inc (int i) {
           return I+i;
       }
   end
   C _assert(), _inc(), _I;
   return _assert(_inc(_I));
\end{verbatim}
}
\rule{8.5cm}{0.37pt}
\caption{ A \CEU program with embedded $C$ definitions.
\label{lst.c}
}
\end{figure}

$C$ calls are fully integrated with the static analysis of 
Section~\ref{sec.ceu.det} and cannot appear in concurrent trails segments, 
given that \CEU has no knowledge about their side effects.
Also, passing variables as parameters counts as read accesses to them, while 
passing pointers counts as write accesses to those types (because functions may 
dereference and assign to them).

This policy increases considerably the number of false positives in the 
analysis, given that many functions can actually be safely called concurrently.
Therefore, \CEU supports syntactic annotations that the programmer can use to 
relax the policy explicitly:

\begin{itemize}
\item The \code{pure} modifier declares a $C$ function that does not cause side 
      effects, allowing it to be called concurrently with any other function in 
the program.
\item The \code{deterministic} modifier declares a pair of variables or 
      functions that do not affect each other, allowing them to be used 
concurrently.
\end{itemize}

The following code illustrates \CEU annotations:

% TODO: exs from ports

{\small
\begin{verbatim}
    pure  _abs();      // 'abs' is side-effect free
    deterministic      // 'led0Toggle' vs 'led1Toggle' is ok
        _Leds_led0Toggle with _Leds_led1Toggle;
    int*  buf1, buf2;  // point to different buffers
    deterministic      // 'buf1' vs 'buf2' is ok
        buf1 with buf2;
\end{verbatim}
}

\begin{comment}
TODO

Annotations are typically write-once declarations (when integrating a $C$ 
service for the first time) to be included in actual applications.
Note that the example in Figure~\ref{lst.blink} should include the annotation 
for \code{\_Leds\_led0Toggle} and \code{\_Leds\_led1Toggle} above to be 
compiled correctly.
\end{comment}

\CEU does not extend the bounded execution analysis to $C$ function calls. 
% which are left as responsibility for the programmer.
% TODO: other languages dont as well
On the one hand, $C$ calls must be carefully analyzed in order to keep programs 
responsive.
On the other hand, they also give the programmer means to circumvent the rigor 
of \CEU in a well-marked way (the special underscore syntax).

\begin{comment}
This approach is also adopted by Esterel, which supports the \code{call} 
primitive to execute code assumed to be instantaneous in the host 
language~\cite{esterel.primer}.
In \CEU, we take a step further and statically detects when such calls may 
execute concurrently, as discussed in the next section.
\end{comment}

Evidently, the programmer should only recur to $C$ for I/O operations that are 
assumed to be instantaneous, but never for control activities.
% (e.g. interrupt handling).

\subsection{Local scopes and finalization}
\label{sec.ceu.local}

Local declarations for variables bring definitions closer to their use in 
programs, increasing the readability and containment of code.
Another benefit, specially in the context of WSNs, is that blocks in sequence 
can share the same memory space, given that they are never active at the same 
time.

The syntactic compositions of trails allows the \CEU compiler to statically 
allocate and optimize memory usage~\cite{wsn.osm}:
memory for trails in parallel must coexist;
trails that follow rejoin points reuse all memory.

However, the unrestricted use of locals introduce subtle bugs when dealing with 
pointers and $C$ functions.
Given that global $C$ functions outlive the scope of locals, a pointer passed 
as parameter may be used after the referred variable goes out of scope, leading 
to a \emph{dangling pointer}.

The code snippet in Figure~\ref{lst.local} was extracted from our port of the 
CTP collection protocol~\cite{wsn.teps} to \CEU.
The protocol contains a complex control hierarchy in which the trail that sends 
beacon frames may be killed or restarted from multiple sources (protocol/radio 
stop, and local/network resend request, all collapsed in lines 3, 5, and 9).

The sending loop (lines 7-18) awakes when the beacon timer expires (line 11).
Note that the message buffer is declared only where it is required (line 12, in 
the 6th depth-level of the program), but its reference is manipulated by two 
$TinyOS$ global functions:
\code{AMSend\_getPayload} (line 13), which gets the data region of the message 
to be prepared (collapsed in line 14);
and \code{AMSend\_send} (line 15), which requests the operating system to 
actually send the message.
As the radio driver runs asynchronously and holds a reference to the message 
until it is completely transmitted, the sending trail may be killed in the 
meantime, resulting in a dangling pointer in the program.

A possible solution is to include a call to \code{AMSend\_cancel} in all trails 
that kill the sending trail.
However, this would require to expand the scope of the message buffer and add a 
state variable to keep track of the sending status, increasing considerably the 
complexity of the application.

\CEU provides a safer and simpler solution with the following rule:
\emph{$C$ calls that receive pointers require a finalization block to safely 
handle variables going out of scope}.
This rule prevents the previous example to compile, forcing the relevant parts 
to be be rewritten as

{\small
\begin{verbatim}
    C nohold _AMSend_getPayload();
        <...>
            var _message_t msg;
            <...>
            finalize
                _AMSend_send(..., &msg, ...);
            with
                _AMSend_cancel(&msg);
            end
        <...>
\end{verbatim}
}

First, the \code{nohold} annotation informs the compiler that the referred $C$ 
function does not require finalization code because it does not hold 
references.
Second, the \code{finalize} construct automatically registers the \code{with} 
clause to execute when the variable passed as parameter in the \code{finalize} 
clause goes out of scope.
This way, regardless of how the sending loop is killed, the finalization code 
always executes and politely informs the OS to cancel the ongoing send 
operation.

\begin{figure}[t]
%\rule{8.5cm}{0.37pt}
{\small
\begin{verbatim}
 1:  <...>
 2:  par/or do
 3:      <...>           // stop the protocol or radio
 4:  with
 5:      <...>           // neighbour request
 6:  with
 7:      loop do
 8:          par/or do
 9:              <...>   // resend
10:          with
11:              await (dt) ms;  // beacon timer expired
12:              var _message_t msg;
13:              payload = _AMSend_getPayload(&msg, ...);
14:              <prepare the message>
15:              _AMSend_send(..., &msg, ...);
16:              await CTP_ROUTE_RADIO_SENDDONE;
17:          end
18:      end
19:  end
\end{verbatim}
}
\rule{8.5cm}{0.37pt}
\caption{ Unsafe use of local references.
\label{lst.local}
}
\end{figure}

\subsection{Wall-clock time}
\label{sec.ceu.time}

Activities that involve reactions to \emph{wall-clock time}%
\footnote{
By wall-clock time we mean the passage of time from the real world, measured in 
hours, minutes, etc.
}
appear in typical patterns of WSNs, such as sensor sampling and timeouts.
However, support for wall-clock time is somewhat low-level in existing 
languages, usually through timer callbacks or sleep blocking calls.

In any concrete system implementation, a requested timeout does not expire 
precisely with zero-delay, a fact that is usually ignored by programmers.
We define the difference between the requested timeout and the actual expiring 
time as the \emph{residual delta time (delta)}.
Without explicit manipulation, the recurrent use of timed activities in 
sequence (or in a loop) might accumulate a considerable amount of deltas that 
could lead to incorrect behavior in programs.

The \code{await} statement of \CEU supports wall-clock time and handles deltas 
automatically, resulting in more robust applications.
As an example, consider the following program:

{\small
\begin{verbatim}
    int v;
    await 10ms;
    v = 1;
    await 1ms;
    v = 2;
\end{verbatim}
}

Suppose that after the first \code{await} request, the underlying system gets 
busy and takes 15ms to check for expiring awaits.
The scheduler will notice that the \code{await 10ms} has not only already 
expired, but delayed with \code{delta=5ms}.
Then, the awaiting trail awakes, sets \code{v=1}, and invokes \code{await 1ms}.
However, the current delta is higher than the requested timeout (i.e. $5ms > 
1ms$), so the trail is immediately rescheduled for execution, now with 
\code{delta=4ms}.

\CEU also takes into account the fact that time is a physical quantity that can 
be added and compared.
For instance, for the program that follows, although \CEU cannot guarantee that 
the first trail terminates exactly in 11ms, it can at least ensure that the 
program always returns $1$:

%\begin{figure}[t]
%\rule{8.5cm}{0.37pt}
{\small
\begin{verbatim}
    par do
        await 10ms;
        <...>         // any non-awaiting sequence
        await  1ms;
        return 1;
    with
        await 12ms;
        return 2;
    end
\end{verbatim}
}
%\rule{8.5cm}{0.37pt}
%\caption{ The first trail always terminates the program.
%\label{lst.time}
%}
%\end{figure}

Remember that any non-awaiting sequence is considered to take no time in the 
synchronous model.
Hence, the first trail is guaranteed to terminate before the second trail, 
because $10+1 < 12$.
A similar program in a language without first-class support for timers, would 
depend on the execution timings for the code marked as \code{<...>}, making the 
reasoning about the execution behavior more difficult.

% TODO: uses in ports
% trickle?

\subsection{Internal events}
\label{sec.ceu.ints}

\CEU provides internal events as a signaling mechanism among trails in 
parallel:
a trail that invokes \code{await~e} can be awaken in the future by a trail that 
invokes \code{emit~e}.

In contrast with external events, which are handled in a queue, internal events 
follow a stack policy.
In practical terms, this means that a trail that emits an internal event pauses 
until all trails awaiting that event completely react to it, continuing to 
execute afterwards.

Another difference to external events is that internal events occur in the same 
reaction chain they are emitted, i.e., an \code{emit} instantaneously matches 
and awakes all correspondent \code{await} statements that were invoked in 
\emph{previous reaction chains}%
\footnote{An \code{await} cannot awake on the same reaction chain it is 
invoked.}.

The stacked execution for internal events introduces support for a restricted 
form of subroutines that cannot express recursive definitions (either directly 
or indirectly), resulting in bounded memory and execution times.
% that preclude stack overflows.
% TODO: exec bounded
% TODO: why?

Figure~\ref{lst.func} shows how the dissemination trail from our port of the 
DRIP protocol to \CEU can be invoked from different parts of the program, just 
like subroutines.
The DRIP protocol distinguishes from data and metadata packets and disseminates 
one or the other based on external requests.
For instance, when the trickle timer expires, the program invokes 
\code{emit~send=0}, which awakes the dissemination trail and starts sending a 
metadata packet.
If the trail is already sending a packet, than the \code{emit} does not match 
the \code{await} and will have no effect (just like the \emph{nesC} 
implementation, which uses a explicit state variable to achieve this behavior).

% TODO: missed sends / non reentrancy

\begin{figure}[t]
%\rule{8.5cm}{0.37pt}
{\small
\begin{verbatim}
event int send;
par do
    <...>
        await DRIP_KEY;
        emit send=1;        // broadcast data
with
    <...>
        await DRIP_TRICKLE;
        emit send=0;        // broadcast meta
with
    <...>
        var _message_t* msg = await DRIP_DATA_RECEIVE;
        <...>
        emit send=1;        // broadcast data
with
    loop do
        var int data? = await send;
        <...>   // send data or metadata
    end
end
\end{verbatim}
}
\rule{8.5cm}{0.37pt}
\caption{ The \code{send} ``subroutine'' is invoked from different parts of the 
program.
\label{lst.func}
}
\end{figure}

Internal events also provide means for describing more elaborate control 
structures, such as \emph{exceptions}.
The code in Figure~\ref{lst.exception} handles incoming packets for the CC2420 
radio driver in a loop (lines 3-17).
After awaking from a new packet notification (line 4), the program enters in a 
sequence to read the bytes from the hardware buffer (lines 8-17).
If any anomaly is found on the received data, the program invokes 
\code{emit~next} to discard the current packet (lines 10,14).
Given the stacked execution for internal events, the \code{emit} invocation is 
stacked, awaking the trail in line 6, which terminates and kills the whole 
\code{par/or} in which the emitting trail is blocked.
This way, the continuation for the \code{emit} never resumes, and the loop 
restarts to await the next packet.

% TODO: resumable

\begin{figure}[t]
%\rule{8.5cm}{0.37pt}
{\small
\begin{verbatim}
 1:    <...>
 2:    event void next;
 3:    loop do
 4:        await CC_RECV_FIFOP;
 5:        par/or do
 6:            await next;
 7:        with
 8:            <...>
 9:            if rxFrameLength > _MAC_PACKET_SIZE then
10:                emit next;  // packet is too large
11:            end
12:            <...>
13:            if rxFrameLength == 0 then
14:                emit next;  // packet is empty
15:            end
16:            <...>
17:        end
18:    end
\end{verbatim}
}
\rule{8.5cm}{0.37pt}
\caption{ The \code{emit} raises an exception caught by the \code{await}.
\label{lst.exception}
}
\end{figure}

\subsection{Code reentrancy}
\label{sec.ceu.oo}

Applications frequently require multiple instances of an abstraction to coexist 
during runtime.
As an example, to keep track of multiple dissemination values, an application 
may create multiple instances of the DRIP protocol which, in turn, each 
requires a local instance of a trickle timer.

Code reentrancy is a technique to avoid duplicating code to save ROM:
the same code is shared among instances, which only differ on their data and
point of execution.

In traditional multi-threaded systems, code reentrancy is achieved with 
function declarations that are executed with different stacks and instruction 
pointers.
In object oriented languages, a \emph{class} encapsulates methods and 
properties, and can be instantiated as objects.

In \CEU, we designed an hybrid approach, which combines threads and classes in 
the so called \emph{organisms}.
An organism class is composed of an \emph{interface} and a single \emph{body}.
The interface exposes public variables and internal events that other organisms 
(and the top-level body) can refer.
The body of a class is equivalent to a trail, having access to all presented 
functionality provided by \CEU, such as parallel compositions, $C$ calls, 
timers, etc.
An organism is instantiated by declaring a variable of the desired class, and 
its body is automatically spawned in a \code{par/or} with the enclosing block.
A method can be simulated by exposing an internal event in the interface of the 
class and using the same technique of Figure~\ref{lst.func}.

The first column of Figure~\ref{lst.orgs} re-implements the example of 
Figure~\ref{lst.all} to blink two LEDs with different frequencies.
The \code{Blink} class exposes the \code{led} and \code{freq} variables to be 
configured by the application, which then creates two instances and initializes 
them.

The second column shows how the organisms bodies are expanded to run in a 
\code{par/or} together with the enclosing block body.
The expansion is illustrative, i.e., the code is not duplicated.
Note that in the expansion, the bodies of the organisms are followed by 
\code{await~FOREVER}%
\footnote{\code{FOREVER} is a reserved keyword in \CEU, and represents an 
external input event that never occurs.}%
, meaning that only the enclosing block can terminate the \code{par/or}.
Note also that the block body runs first and properly initializes the organisms 
before they are spawned.

Once the enclosing block terminates, declared organisms are killed and all 
memory can be reused, just as happens in standard parallel compositions.
The allocation and deallocation of organisms is static, with no runtime 
overhead such as garbage collection.

\begin{figure}[t]
%\rule{8.5cm}{0.37pt}
\begin{minipage}[t]{0.45\linewidth}
{\small
\begin{verbatim}
C _on(), _off();

class Blink with
   var int led;
   var int freq;
do
   loop do
      _on(this.led);
      await (this.freq)s;
      _off(this.led);
      await (this.freq/2)s;
   end
end

var Blink b1;
b1.led  = 0;
b1.freq = 2;

var Blink b2;
b2.led  = 1;
b2.freq = 4;

await 1min;
\end{verbatim}
}
\end{minipage}
%
\hspace{0.0cm}
%
\begin{minipage}[t]{0.45\linewidth}
%\fbox{
{\small
\begin{verbatim}
C _on(), _off();
var Blink b1, b2;
par/or do
   b1.led  = 0;
   b1.freq = 2;
   b2.led  = 1;
   b2.freq = 4;
   await 1min;
with
   loop do
      _on(b1.led);
      await (b1.freq)s;
      _off(b1.led);
      await (b1.freq/2)s;
   end
   await FOREVER;
with
   loop do
      _on(b2.led);
      await (b2.freq)s;
      _off(b2.led);
      await (b2.freq/2)s;
   end
   await FOREVER;
end
\end{verbatim}
%}
}
\end{minipage}
\rule{8.5cm}{0.37pt}
\caption{ ``Two blinking LEDs'' using organisms.
\label{lst.orgs}
}
\end{figure}

Figure~\ref{lst.srp} shows part of our port of the SRP routing 
protocol~\cite{wsn.teps} to \CEU.
The protocol specifies a fixed number of \emph{forwarders} responsible for 
routing received messages to neighbours based on a static table.
Given that a forwarder holds internal state (i.e. a message buffer and the 
forwarding activity), we define a \code{Forwarder} class and create multiple 
instances to serve requests.

The first column of Figure~\ref{lst.srp} shows the receiving loop of the 
protocol, which invokes \code{emit~go} when a message needs to be forwarded.
The event is declared as global, so that \code{Forwarder} instances have access 
to it.
The forwarders are declared in a vector, creating \code{COUNT} different 
instances.
As the vector is local, all instances are automatically killed when the 
protocol is stopped.
(Note the use of the start/stop pattern of Figure~\ref{lst.radio} again.)

The second column of Figure~\ref{lst.srp} shows the \code{Forwarder} class.
Initially, all forwarders are in the same state, waiting for the global event 
\code{go}.
Once the receiving loop emits the event in the top-level body, the forwarders 
awake in the order they were declared.
The first forwarder atomically sets the \code{gotcha} variable, indicating that 
the message will be handled and that other forwarders should ignore it:
all other forwarders will await again for the next \code{go} emission.
With this technique, we eliminated the need of an explicit queue.
In the case that all forwarders become busy, the \code{go} emission will be 
missed (with \code{gotcha=0}), acting just like a full queue.

\begin{comment}
Note that \CEU organisms are not global entities and do not use the heap for 
memory.
Instead, they are bounded to the scope they are declared, and all memory is 
statically allocated, just like \CEU does for standard local variables.
Also, when an organism goes out of scope, the same automatic bookkeeping of 
\code{par/or} compositions holds, all internal trails are killed and 
finalization blocks execute (if any).
Hence, the ``garbage collection'' for both the memory and code in organisms is 
efficient and static.
Although \CEU does not support dynamic creation (which could lead do unbounded 
memory), scoped organisms offer some degree of flexibility when compared to 
systems providing global objects only~\cite{wsn.virgil,wsn.flowtalk}.
\end{comment}

% TODO: ND access

\begin{figure}[t]
%\rule{8.5cm}{0.37pt}
\begin{minipage}[t]{0.45\linewidth}
{\small
\begin{verbatim}
event _fwd_t go;
loop do
  await SRP_START;
  par/or do
    await SRP_STOP;
  with
    var Forwarder[COUNT] fwds;
    <initialize fwds>
    loop do
      await SRP_RECEIVE;
      <receive or forward>
      if hops_left > 0 then
        <prepare fwd>
        emit go=&fwd;
      end
    end
  end
end
\end{verbatim}
}
\end{minipage}
%
\hspace{0.0cm}
%
\begin{minipage}[t]{0.45\linewidth}
%\fbox{
{\small
\begin{verbatim}
class Forwarder with
  <...>
do
  loop do
    fwd = await global:go;
    if fwd:gotcha then
      continue;
    end
    fwd:gotcha = 1;
    <send message>
    <...>
  end
end
\end{verbatim}
%}
}
\end{minipage}
\rule{8.5cm}{0.37pt}
\caption{ SRP forwarders as organisms.
\label{lst.srp}
}
\end{figure}

\begin{comment}
Objects
    - each method is a global function receiving a different object to 
      manipulate
    - global (usually heap)
    - garbage collected or global

Organisms
    - mutual reactivity
    - scoped / local
    - O(1) GC

- nesting
    - data
    - events
    - listeners
    - compositions

- both have an interface
- fields / methods

- fields / internal events
- public fields are ok because reliable shared memory

- no recursive definitions
- but we have interfaces
- special global interface
\end{comment}

%\subsection{Limitations}
\subsection{Implementation}

%\newpage
\section{Evaluation}
\label{sec.eval}

\begin{figure*}[t]
\includegraphics[width=\textwidth]{eval.png}
\caption{ Comparison between \CEU and \emph{nesC} for the ported applications.
\label{fig.eval}
}
\end{figure*}

In order to evaluate the applicability of \CEU in the context of WSNs, we 
ported a number of pre-existing protocols and system utilities in the TinyOS 
operating system~\cite{wsn.tos}, which are all written in 
\emph{nesC}~\cite{wsn.nesc}.
We chose \emph{nesC} in our evaluation given the availability and maturity of 
open-source implementations, and because it is also used as the base of 
comparison in many related works to \CEU 
(\cite{wsn.protothreads,wsn.sol,wsn.ocram,wsn.flowtalk}).

We ported the following applications to \CEU%
\footnote{The source code for both \CEU and \emph{nesC} can be found at
\url{github.com/xxx/}.}:
the \emph{Trickle} timer~\cite{wsn.trickle};
the receiving component of the \emph{CC2420} radio driver~\cite{wsn.teps};
the \emph{DRIP} dissemination protocol~\cite{wsn.teps};
the \emph{SRP} routing protocol~\cite{wsn.teps};
the routing component of the \emph{CTP} collection protocol~\cite{wsn.ctp}.

We took advantage of the component-based model of TinyOS and all of our ports 
use the same interface provided by the \emph{nesC} counterpart---
changing from one implementation to the other is done by changing a single 
file.
This way, we could also use existing test applications available in the TinyOS 
repository (e.g. \emph{TestDissemination}, \emph{TestNetwork}, etc.).
Furthermore, retaining the same architecture made easier to mimic the 
functionality between the implementations.

Figure~\ref{fig.eval} shows the comparison of \emph{resource usage} and 
\emph{code complexity}, which are discussed in detail in
Sections~\ref{sec.eval.resource}~and~\ref{sec.eval.code}, respectively.
We also detail which features of \CEU have been used in the ports, for a more 
qualitative discussion.
Note that all proposed features appear in at least two of the ported 
applications.

\begin{comment}
TODO

However, without architectural changes, we could not express XXX how.
more lines, more ROM
    - not always represent the Cu way
        - full DRIP 40%

and is used  works (e.g. \cite{wsn.protothreads,wsn.sol,wsn.flask}) already 
        include comparisons to nesc, allowing (at least) an indirect comparison 
of \CEU{} with them.

\footnote {
    We used $TinyOS-2.1.1$ and $micaz$ motes, and the sample applications found 
in \code{/opt/tinyos-2.1.1/apps/}.
}
\end{comment}

\subsection{Resource usage}
\label{sec.eval.resource}

% TODO: testnetwork, somente CTP(!)

% important bla bla bla
% results indicate a good design, features "se encaixam", no bloat

% limitation
% hard real-time
% theoretical limitation?
% radio throughput is the critical in WSNs
% packet losses involve retransmissions which are expensive

%We conclude that local scopes are currently more important as a programming 
%XXX than to actually a mechanism to reuse memory.
%we checked, all in parallel
%Similar results from evaluations in related work~\cite{wsn.ocram,wsn.sol}

% nesC uses less RAM than \emph{all}.
% two apps in sequence

\subsection{Code complexity}
\label{sec.eval.code}

To measure the code complexity between the implementations in \CEU and 
\emph{nesC}, we used the number of tokens present in the source code as the 
main metric.
We chose to use tokens instead of lines of code because the code density is 
considerably lower in \CEU, given that most lines are composed of a single 
block delimiter from a structural composition.
Note that the languages share the core syntax for expressions, calls, and field 
accessors (based on $C$), and we removed all verbose annotations from the 
\emph{nesC} implementations, which are not present in \CEU (e.g. \code{signal}, 
\code{call}, \code{command}, etc.) for a fair comparison.

Similarly to comparisons from related works~\cite{wsn.ocram,wsn.protothreads}, 
we did not consider code shared among the implementations, as they do not 
represent control functionality and pose no challenges regarding concurrency 
aspects (e.g. predicates, packet accessors, etc.).

Figure~\ref{fig.eval} shows a considerable decrease in the number of tokens for 
all ported applications (from 20\% up to 70\%).

As a second metric, we counted the number of global variables used in the 
implementations.
The globals were categorized in \emph{state} and \emph{data} variables.

State variables are used as a mechanism to control the application flow (on the 
lack of a better primitive).
Keeping track of them is regarded as a difficult task, hence, reduction of 
state variables has already been proposed as a metric of code complexity in a 
related work~\cite{wsn.protothreads}.
In \CEU implementations, state variables were reduced to zero, as all control 
patterns could be expressed with hierarchical compositions of activities.

Data variables in WSNs are usually used to hold message buffers and protocol 
parameters (e.g. sequence numbers, timer intervals, etc.).
In event-driven systems, given that stacks are not retained across reactions to 
the environment, all data variables must be global%
\footnote{In the case of \emph{nesC}, we refer to globals as all variables 
defined in the top-level of a component implementation block (which are visible 
to all functions inside the component).}.
Although the use of local variables does not incur in reduction of lines of 
code (or tokens), we believe that the smallest the scope of a variable, the 
more readable and less susceptible to bugs the program becomes.

In \CEU implementations, most variables could be nested to a deeper scope.
The column \emph{locals} in Figure~\ref{fig.eval} shows the depth of each 
global that became a local variable in \CEU (where depth=0 is a global 
variable).

The columns below \emph{C\'eu features} in Figure~\ref{fig.eval} point how many 
times each functionality has been used in the ports, helping on identifying 
where the reduction in complexity comes from.
As an example, the \emph{Trickle} timer is abstracted as a class that uses 2 
timers and 3 parallel compositions, with at most 6 trails active at the same 
time (a \code{par} may spawn more than 2 trails).

% TODO: DRIP uses trickle as a service (does not implement it)

\subsection{Safety}

The send/cancel pattern occurs in all ported applications that use the radio 
for communication evaluated in Section~\ref{sec.eval}.
% TODO: expand


* static analysis

given that the porting process was straghtforward, we believe that the 
\emph{nesC} implementation is free of such ...
However, .
another endorsement

- exception srp queue
we know exactly the place where it occurs
nesC no

* cancel

* timers

* locals

%\subsection{Discussion}

%- motivations and qualitative analysis for features on Sec-3

\section{Related work}
\label{sec.related}

\begin{figure*}[t]
\includegraphics[width=\textwidth]{related.png}
\caption{ Table of features found in related works to \CEU.
\label{fig.related}
}
\end{figure*}

Figure~\ref{fig.related} presents an overview of related works to \CEU, 
pointing support for specific features XXX, which are discussed individually.
Although Esterel~\cite{esterel.ieee91} is not targeted at WSNs, we included it 
given its strong influence on \CEU and many related works.
The second line, \emph{Preemptive}, represents all multi-threaded languages 
with preemptive scheduling~\cite{wsn.mantisos,Y,Z}.
The remaining lines enumerate languages with similar goals of \CEU that also 
follow a synchronous or cooperative execution semantics (they are sorted by the 
date they first appear in a publication).

The three columns under \emph{Composition} indicate which languages provide
abstractions to deal with \emph{sequential} and \emph{parallel} compositions of 
activities, as well as \emph{internal communication} among them.
Esterel first introduced hierarchical compositions of processes, which first 
appeared in the context of WSNs in Protothreads~\cite{wsn.protothreads} and 
Sol~\cite{wsn.sol} (indicated by the gray background).
\CEU differs from these on the stack-based semantics for internal events, which 
is essential to bring other control mechanisms, such as exceptions, as 
discussed in Section~\ref{sec.ceu.ints}.
It is known that languages with preemptive scheduling cannot express thread 
termination safely~\cite{esterel.preemption,sync_async.threadsstop}, being 
unsuitable for a \code{par/or} construct.

The two columns under \emph{Memory} list language support for \emph{code 
reentrancy} and \emph{local scopes} for variables, which account for saving ROM 
and RAM, respectively.
Both properties are easily achieved in traditional multi-threaded systems, in 
which threads share global functions as bodies, with each holding a different 
stack.
However, this approach is not resource-efficient, given that the compiler 
cannot infer when each thread is active, enforcing all to be statically 
allocated~\cite{wsn.mantisos,wsn.ocram} (even if some of them are never active 
at the same time).
\emph{nesC} provides compile-time instantiable components, which resemble 
classes from object-oriented programming.
As discussed in Section~\ref{sec.ceu.oo}, \CEU organisms introduce an hybrid 
approach, providing TODO.
\CEU support for local scopes is very similar to how OSM~\cite{wsn.osm} does.

TODO
Esterel derived cannot offer the analysis

TODO
Although \CEU does not support dynamic creation (which could lead do unbounded 
memory), scoped organisms offer some degree of flexibility when compared to 
systems providing global objects only~\cite{wsn.virgil,wsn.flowtalk}.
\section{Conclusion}
\label{sec.conclusion}

% most safety guarantees actually make the programming experience more 
% expressive

\begin{comment}
CONCLUSION
Note that one of the main objectives of \CEU is to enhance safety in concurrent 
patterns, in the sense that if the programmer sticks to \CEU primitives for 
control patterns it will gain...
avoid cycles
The stack execution policy for internal events can express nested emits, and 
also avoids dependency cycles in programs.

In \CEU, there are three possible sources of non-determinism:
\emph{concurrent access to variables} (e.g. \code{(1=>a\&\&2=>a)}),
\emph{concurrent \emph{par/or} termination} (e.g. \code{(1||2)=>a}, might yield 
$1$ or $2$), and \emph{concurrent loop escape}%
\footnote{ The token \brk{} escapes the innermost loop with its preceding 
expression. }
(e.g. \code{(1\brk{} \&\& 2\brk)* =>a}).

During compile time, \CEU{} converts programs into deterministic finite 
automatons in order to detect the three forms of non-determinism.
This conversion is the reason why \CEU{} is a static language.
% TODO: claim
A DFA unequivocally represents a \CEU{} program, covering exactly all possible 
paths it can reach during runtime.
For instance, the following program is identified as non-deterministic, because 
the variable $v$ is accessed concurrently on the 6th occurrence of the event 
$A$:

\Code{
(\til{}A; \til{}A; 1=>v)*
\&\&
(\til{}A; \til{}A; \til{}A; v)*
}

\end{comment}

\begin{comment}
% BACKGROUND

- hard vs soft real-time

% MOTIVATION

- Safety:
    "

% BENCHMARKS

- TinyOS
    - minimization and prevention [decade]
        - minimizing resource   (constraint)
        - preventing bugs       (constraint)
    - isolation
        - not in protothreads
        - static
        - "it makes each component's interaction to an underlying shared 
          resource completely independent"

    - EFICIENCY: minimization
    - SAFETY: prevention, isolation
    - EXPRESSIVENESS: isolation

- Protothreads
    - state machines removal
    - solves sequential execution
    - subsequent alternatives are similar
    - wide use
    - available
    - represents all alternatives that follows the right approach
        (synchronous concurrency)

    - no isolation

    - EXPRESSIVENESS: state machines
    - SAFETY: ?
    - in terms of safety not many gains, still shared-globals (isolation),

% CONTRIBUTIONS

- thinked together
- both aspects are embraced in a single design:
    - safety is not possible w/o extra information aquired from high-level
    - high-level is not possible w/o safety
    - ex.
        - par/or w/ stacked internal emits for killing
        - par for shared-memory
        - shared-memory analysis is not possible w/o par

% DESIGN

- timers
    - exemplo da chamada periodica a alarme que avoids ""

% EVALUATION

    - we sticked to the component model
        - protothreads rewrote?
        - if we rewrite? (drip gains)

    - lines/tokens

    - states

    - other globals

    - features used in examples: par/or/and, wclocks, OO

    - finally p/ cancelar mensagens (timers, evts, nao precisa)
    - mais uma razao para ter timers de 1a classe (sao cancelados 
      automaticamente)
    - procurar nos exs. do tinyOS por TODOs relacionados a isso

- send  hold
    finally p/ cancelar
- receive  nohold

In the XXX protocol a message to XXX needs is sent whenever XXX.
In the code snippet that follows, the declaration of the messasge buffer is 
local and is N levels of depth to the top-level block of the code.
Hence, much more readable than having a global that you cannot say where it is 
used if not inspecting the whole code.

internal events are needed to eliminate state when they occur in the middle of 
a par trail (i.e., the trail is not signaling with its termination)

However,.

    - isolation
        - eliminated queues and pools
            - full queue is equivalent to miss an event

- CTP exemplo radio? / ctp? (4 estados) transformados em start/stop (que 
  carregam uma semantica) // controle dessas variaveis totalmente localizado em 
paralelo com o programa, sem globais

par/and p/ evitar chamadas que retornam erro:

Timer.periodic(XXX)
Timer.fired() {
    if (call AMSend.send()) {
        ...
    }
}

await XXX;
loop do
    par/and do
        await XXX;
    with
        AMSend.send();
        await SEND\_DONE;
    end
end

-- se ha multiplos:

await XXX;
loop do
    par/and do
        await XXX;
    with
        loop do
            AMSend.send();
            await SEND\_DONE;
            if me then
                break;
            end
        end
    end
end

-- FINALIZE

%find . -name "*.nc" | xargs egrep -R "\.send\(|\.send \(" | grep -v command | 
%wc
%=> 349

%find . -name "*.nc" | xargs egrep -R "\.cancel\(|\.cancel \(" | grep -v 
%command | wc
%=> 49

Bug in SRP:
- usually in TinyOS, decrease in performance, waste of radio, but buffer is 
  global
HOWEVER:
- client takes a message from MessagePool

related: lembrar que PROTO e OCRAM tm sequential composition
    PT\_SPAWN e normal call

\end{comment}

\begin{comment}
Figure~\ref{lst.ctp} shows how we use internal events to abstract the 
start/stop operations for our port of the CTP collection 
protocol~\cite{wsn.teps} to \CEU.

The first column of Figure~\ref{lst.ctp} declares the internal events and 
mimics the start/stop pattern used for the radio driver in 
Figure~\ref{lst.radio}.
In parallel, we define the actual behavior for the operations (expanded in the 
second column), which depend not only from external requests to start/stop the 
protocol but also from the radio status.

The second column keeps track of the current external state through the local 
variables \code{ctp?} and \code{radio?}%
\footnote{\CEU allows the symbol \code{?} in identifiers.}
and emits the appropriate event when TODO, multiplexing four external events 
into two internal events.

\begin{figure}[t]
%\rule{8.5cm}{0.37pt}
\begin{minipage}[t]{0.45\linewidth}
{\small
\begin{verbatim}
event void start;
event void stop;
par do
  // start/stop pattern
  loop do
    await start;
    par/or do
      await stop;
    with
      // executes CTP
      <...>
    end
  end
with
  <code to emit start/stop>
end
\end{verbatim}
}
\end{minipage}
%
\hspace{0.0cm}
%
\begin{minipage}[t]{0.45\linewidth}
%\fbox{
{\small
\begin{verbatim}
// <code to emit start/stop>
var int ctp?   = 0;
var int radio? = 0;
loop do
  par/or do
    await CTP_START;
    ctp? = 1;
  with
    await CTP_STOP;
    ctp? = 0;
  with
    await RADIO_STARTDONE;
    radio? = 1;
  with
    await RADIO_STOPDONE;
    radio? = 0;
  end
  if ctp? and radio? then
    emit start;
  else
    emit stop;
  end
end
\end{verbatim}
%}
}
\end{minipage}
\rule{8.5cm}{0.37pt}
\caption{ Start/stop behavior for the CTP protocol.
\label{lst.ctp}
}
\end{figure}

\begin{minipage}[t]{0.20\linewidth}
{\small
\begin{verbatim}
/* PROTOTHREADS IMPLEMENTATION */
PT_THREAD blink0 (<...>) {
  static struct timer timer;
  PT_BEGIN();
  while (1) {
    timer_set(&timer, 250);
    PT_WAIT_UNTIL(timer_expired(&timer));
    leds_toggle(LEDS_RED);
  }
  PT_END();
}
PT_THREAD blink1 (<...>) {
  static struct timer timer;
  PT_BEGIN();
  while (1) {
    timer_set(&timer, 500);
    PT_WAIT_UNTIL(timer_expired(&timer));
    leds_toggle(LEDS_GREEN);
  }
  PT_END();
}
int main (void) {
  static struct timer timer;
  PT_INIT(&blink0);
  PT_INIT(&blink1);
  timer_set(&timer, 60000);
  while (
    PT_SCHEDULE(blink0()) &&
    PT_SCHEDULE(blink1()) &&
    !timer_expired(timer)
  );
  leds_off(LEDS_ALL);
  <...> // CONTINUE
}

\end{verbatim}
}
\end{minipage}
%
\hspace{0.0cm}
%
\begin{figure*}[t]
%\rule{8.5cm}{0.37pt}
\begin{minipage}[t]{0.22\linewidth}
{\small
\begin{verbatim}
/* NESC IMPLEMENTATION */
event void Boot.booted () {
  call T0.startOneShot(0);
  call T1.startOneShot(0);
  call T2.startOneShot(60000);
}
event void T0.fired () {
  call Leds.led0Toggle();
  call T0.startOneShot(250);
}
event void T1.fired () {
  call Leds.led1Toggle();
  call T0.startOneShot(500);
}
event void T2.fired () {
  call T0.cancel();
  call T1.cancel();
  call Leds.set(0);
  <...> // CONTINUE
}
\end{verbatim}
}
\end{minipage}
%
\hspace{0.0cm}
%
\begin{minipage}[t]{0.20\linewidth}
{\small
\begin{verbatim}
/* MANTISOS IMPLEMENTATION */
static int ended;
void blink0 () {
  uint32_t dt = 250;
  while (!ended) {
    mos_led_toggle(0);
    mos_thread_sleep(dt);
  }
}
void blink1 () {
  uint32_t dt = 500;
  while (!ended) {
    mos_led_toggle(1);
    mos_thread_sleep(dt);
  }
}
void main () {
  ended = 0;
  mos_thread_new(blink0);
  mos_thread_new(blink1);
  mos_thread_sleep(60000);
  ended = 1;
  mos_led_display(0);
  <...> // CONTINUE
}
\end{verbatim}
}
\end{minipage}
%
\hspace{0.0cm}
%
\begin{minipage}[t]{0.20\linewidth}
%\fbox{
{\small
\begin{verbatim}
/* OCRAM IMPLEMENTATION */
static int ended;
THREAD void blink0 () {
  uint32_t now = tc_time();
  while (!ended) {
    tc_toggle_led_0();
    tc_sleep(now+=250);
  }
}
THREAD void blink1() {
  uint32_t now = tc_time();
  while (!ended) {
    tc_toggle_led_1();
    tc_sleep(now+=500);
  }
}
THREAD void main () {
  ended = 0;
  // blink0 auto starts
  // blink1 auto starts
  tc_sleep(tc_time()+60000);
  ended = 1;
  tc_set_leds(0);
  <...> // CONTINUE
}
\end{verbatim}
%}
}
\end{minipage}
%
\hspace{0.0cm}
%
\begin{minipage}[t]{0.18\linewidth}
%\fbox{
{\small
\begin{verbatim}
/* CEU IMPLEMENTATION */
par/or do
   loop do
      _Leds_led0Toggle();
      await 250ms;
   end
with
   loop do
      _Leds_led1Toggle();
      await 500ms;
   end
with
   await 1min;
end
_Leds_set(0);
<...> // CONTINUE
\end{verbatim}
%}
}
\end{minipage}
\rule{18cm}{0.37pt}
\caption{ ``Two blinking LEDs'' in
    nesC~\cite{wsn.nesc},
    MantisOS~\cite{wsn.mantisos},
    Ocram~\cite{wsn.ocram},
    and \CEU.
\label{lst.all}
}
\end{figure*}

\begin{figure}[t]
%\rule{8.5cm}{0.37pt}
\begin{minipage}[t]{0.50\linewidth}
{\small
\begin{verbatim}
 // Ocram implementation
 THREAD void blink1() {
    int now = tc_time();
    while(1) {
       now += 250;
       tc_sleep(now);
       tc_toggle_led_0();
    }
 }
 THREAD void blink2() {
    int now = tc_time();
    while(1) {
       now += 500;
       tc_sleep(now);
       tc_toggle_led_1();
    }
 }
\end{verbatim}
}
\end{minipage}
%
\hspace{0.0cm}
%
\begin{minipage}[t]{0.40\linewidth}
%\fbox{
{\small
\begin{verbatim}
// Ceu implementation
par do
   // blink 1
   loop do
      await 250ms;
      _Leds_led0Toggle();
   end
with
   // blink 2
   loop do
      await 500ms;
      _Leds_led1Toggle();
   end
end
\end{verbatim}
%}
}
\end{minipage}
\rule{8.5cm}{0.37pt}
\caption{ ``Two blinking LEDs'' in Ocram and \CEU.
\label{lst.blink}
}
\end{figure}

Figure~\ref{lst.blink} illustrates this difference, showing the implementations 
for two blinking LEDs with both approaches.

In the Ocram~\cite{wsn.ocram} implementation, the two threads are defined as 
global functions and must be controlled manually, i.e.,
the decision to start or terminate each is independent of one another and up to 
the programmer.

In the \CEU implementation, the two trails are syntactically tied together 
inside a \code{par} composition, implying that
(a) they can only exist together;
(b) they always start together
(c) if they terminate, they do it together.

Besides the arguably cleaner syntax, the additional control-flow information 
provided in the program is the base for all features and safety guarantees 
introduced by \CEU.

The \code{par} composition is used when the trails are intended to run forever, 
but \CEU also provides compositions that logically combine trails:
a \code{par/or}  terminates (rejoins) when any of its trails terminates;
a \code{par/and}, only when all terminate;

Although the two multi-threaded implementations look syntactically the same, 
the underlying execution semantics provided by the languages is fundamentally 
different.

On the one hand, preemptive multi-threading provides better responsiveness for 
time critical applications~\cite{wsn.comparison}.
On the other hand, as exemplified in the example, the inherent 
non-deterministic scheduling demands a larger (and error-prone) effort with 
synchronization issues when compared to the simpler run-to-completion semantics 
of cooperative multi-threading.
In the context of WSNs, the safety aspects have been more critical than 
real-time guarantees, since applications are already built on top of 
unpredictable network links~\cite{wsn.decade}.

The conversion between
straightforward \emph{stubs} that translate a \emph{nesC} event into a \CEU 
input event and that exposes \emph{nesC} commands as $C$ functions.
Figure~\ref{}

{\small
\begin{verbatim}
    #define ceu_out_event_TRICKLE_FIRED(i) \
        signal TrickleTimer.fired[*i]();

    #define Random_rand16() \
        call Random.rand16()

    #include "_ceu_defs.h"
    #include "_ceu_code.cceu"

    command error_t Init.init() {
        ceu_go_init();
        return SUCCESS;
    }

    command error_t TrickleTimer.start[uint8_t id]() {
        ceu_go_event(IN_TRICKLE_START, &id);
        return SUCCESS;
    }

    command void TrickleTimer.stop[uint8_t id]() {
        ceu_go_event(IN_TRICKLE_STOP, &id);
    }
\end{verbatim}
}

In Esterel, time is defined as discrete reaction steps in which multiple 
external signals (events in \CEU) can be queried on their presence status.
This semantics has more proximity with that of electronic circuits, but 
simultaneous events would inhibit the temporal analysis of \CEU.
For instance, variable manipulation in Esterel is restricted to a single 
process (trail in \CEU).




\end{comment}

\balance
%{\footnotesize
\bibliographystyle{abbrv}
\bibliography{other}
%}

\end{document}
