\documentclass[10pt]{sensys-proc}

%\usepackage{afterpage}
\usepackage{balance}
\usepackage{color}
\usepackage{fancyvrb}
\usepackage{listings}
\usepackage[utf8]{inputenc}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{verbatim}
\usepackage{xspace}
%\usepackage{amssymb}
%\usepackage{amsmath}
%\usepackage{fancyvrb}
%\usepackage{booktabs}
%\usepackage{colortbl}
%\usepackage{tabularx}
%\usepackage{multirow}
%\usepackage{color}
%\usepackage{hyperref}    % Creates hyperlinks from ref/cite 
%\hypersetup{pdfstartview=FitH}
\usepackage{graphicx}
\usepackage{url}

\newcommand{\footnoteremember}[2]{%
\footnote{#2}%
\newcounter{#1}%
\setcounter{#1}{\value{footnote}}%
}
\newcommand{\footnoterecall}[1]{%
\footnotemark[\value{#1}]%
}

%\renewcommand{\arraystretch}{1.2} % Space out rows in tables

\setlength\paperheight {11in}
\setlength\paperwidth {8.5in}

% No space between bibliography items:
\let\oldthebibliography=\thebibliography
  \let\endoldthebibliography=\endthebibliography
  \renewenvironment{thebibliography}[1]{%
    \begin{oldthebibliography}{#1}%
      \setlength{\parskip}{0ex}%
      \setlength{\itemsep}{0ex}%
  }%
  {%
    \end{oldthebibliography}%
  }
\setlength{\parindent}{5mm}

\newcommand{\compresslist}{
	\setlength{\itemsep}{1pt}
	\setlength{\parskip}{0pt}
	\setlength{\parsep}{0pt}
}

\newenvironment{itemize*}%
  {\begin{itemize}%
    \setlength{\itemsep}{0pt}%
    \setlength{\parskip}{0pt}}%
  {\end{itemize}}
\usepackage{enumitem}
\setlist{nolistsep}

%\relpenalty=9999
%\binoppenalty=9999

\newcommand{\CEU}{\textsc{C\'{e}u}\xspace}
\newcommand{\code}[1] {{\small{\texttt{#1}}}}
\newcommand{\Code}[1] {\texttt{#1}}

\def\sharedaffiliation{%
\end{tabular}
\begin{tabular}{c}
}

\numberofauthors{5}
\author{
    \alignauthor Francisco Sant'Anna        \\
        \email{fsantanna@inf.puc-rio.br}
    \alignauthor Noemi Rodriguez            \\
        \email{noemi@inf.puc-rio.br}
    \alignauthor Roberto Ierusalimschy      \\
        \email{roberto@inf.puc-rio.br}
    \sharedaffiliation
    \affaddr{Departamento de Inform\'atica --
             PUC-Rio, Brazil}
\vspace{0.5cm}
\and
    \alignauthor Olaf Landsiedel \\
         \email{olafl@chalmers.se}
    \alignauthor Philippas Tsigas \\
         \email{tsigas@chalmers.se}
    \sharedaffiliation
    \affaddr{Computer Science and Engineering --
             Chalmers University of Technology, Sweden}
}

%\title{Safe Concurrent Abstractions for Wireless Sensor Networks}
%\title{Safe Synchronous Abstractions for Wireless Sensor Networks}
\title{Safe System-level Concurrency for Resource-Constrained Motes}

%\crdata{978-1-4503-1169-4}
%\conferenceinfo{SenSys'13,} {November X--X, 2013, Rome, Italy.}
%\CopyrightYear{2013}

\begin{document}

\maketitle

% TODO: CTP / DRIP ROM reduction

\begin{abstract}

% TODO: split 2 sents.
%Although there has been much research in facilitating programming WSNs,
Despite the continuous research in facilitating programming WSNs,
most safety analysis and mitigation efforts in control and concurrency are 
still left to programmers, who must explicitly manage synchronization and 
shared memory.
% among activities.
%
We present a system language that ensures safe concurrency by enforcing the 
handling of threats at compile time, rather than at runtime.
%
On the one hand, the synchronous and static foundation of our design allows for 
a simple reasoning about concurrency that enables a compile-time analysis to 
ensure deterministic and memory-safe programs.
On the other hand, this design imposes limitations on the language 
expressiveness, such as for doing computation-intensive operations and meeting 
hard real-time responsiveness.
% defining, doing, executing, describing
%
Nevertheless, we implemented a number of standard network protocols and a radio 
driver in order to show that the achieved expressiveness and responsiveness is 
sufficient for a wide range of WSNs applications.
%
Besides the ensured safety properties, the implementations show a reduction 
around 25\% in code complexity, with a penalty of memory increase below 10\% in 
terms of total ROM and RAM needs.
% in terms of total ROM/RAM.
%, and a negligible increase in CPU usage.

\end{abstract}

% A category with the (minimum) three required fields
%\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, 
%performance measures]

%\terms{Delphi theory}

%\keywords{ACM proceedings, \LaTeX, text tagging}

%\category{D.3}{Programming Languages}{General}
\category{D.3.3}{Programming Languages}{Language Constructs and Features}

\terms{Design, Languages, Reliability}

\keywords{Concurrency, Determinism, Safety, Static Analysis, Synchronous, 
Wireless Sensor Networks}

\section{Introduction}
\label{sec.intro}

\begin{comment}
TODO
Wireless sensor networks (WSNs) are composed of a large number of tiny devices 
(known as ``motes'') capable of sensing the environment and communicating among 
them.
WSNs are usually employed to continuously monitor physical phenomena in large 
or unreachable areas, such as wildfire in forests and air temperature in 
buildings.
Each mote features limited processing capabilities, a short-range radio link, 
and one or more sensors (e.g. light and temperature) \cite{wsn.survey}.

Applications developed for wireless sensor networks (WSNs) typically perform a 
succession of sensing, processing, actuating, and communicating.
This process involves an external environment, which concurrently interacts 
with the application by issuing events that represent expiring timers, messages 
arrivals, sensor readings, etc.
\end{comment}

System-level development for WSNs basically consists of abstracting access to 
the hardware and designing specially tweaked network 
protocols~\cite{wsn.tos,wsn.survey} to be further integrated as services in 
higher-level applications or macro-programming systems~\cite{wsn.state_of_art}.
%The external environment plays an important, as it interacts with applications 
%permanently (and concurrently) by issuing events that represent expiring 
%timers, messages arrivals, sensor readings, etc.
If (hard) timeliness cannot be met by WSNs applications, given their networked 
nature, it is still paramount to have a reliable programming environment, 
pushing to compile-time as much safety guarantees as 
possible~\cite{wsn.decade}.

Three major programming models have been proposed for system-level development 
in WSNs: the \emph{event-driven}, \emph{multi-threaded}, and \emph{synchronous} 
models.
%
In event-driven programming \cite{wsn.tos,wsn.contiki}, each external event can 
be associated with a short-lived function callback to handle a reaction to the 
environment.
This model is efficient for the severe resource constraints of WSNs, but is 
known to be difficult to 
program~\cite{sync_async.cooperative,wsn.protothreads}.
%
Multi-threaded systems emerged as an alternative, providing traditional 
structured programming for WSNs (e.g.~\cite{wsn.protothreads,wsn.mantisos}).
However, the development process still requires manual synchronization and 
bookkeeping of threads (e.g. create, start, and 
rejoin)~\cite{sync_async.threadsproblems}.
%
Synchronous languages~\cite{rp.twelve} have also been successfully adapted to 
WSNs and offer higher-level compositions of activities, considerably reducing 
programming efforts~\cite{wsn.sol,wsn.osm}.

Despite the increase in development productivity, languages still lack
effective safety guarantees to build complex concurrent applications.
%
As an example, shared memory is widely used as a low-level communication 
mechanism, but current languages do not go beyond atomic access guarantees, 
either explicitly through synchronization 
primitives~\cite{wsn.mantisos,wsn.tinythreads}, or implicitly with cooperative 
scheduling~\cite{wsn.sol,wsn.nesc}.
Requiring manual synchronization leads to potential safety 
hazards~\cite{sync_async.threadsproblems}, while implicit synchronization is no 
less questionable, as it assumes that \emph{all} accesses are dangerous.
The bottom line is that existing languages cannot detect and enforce atomicity 
only when they are required.
%
Furthermore, system-level development typically involves accesses to the 
underlying platform through $C$ system calls that hold pointers for some time
(e.g. transmission of a message buffer).
Hence, if a local variable goes out of scope and its reference has been 
exposed, a system-level activity may end up with a dangling pointer (i.e. a 
pointer to freed memory).

\begin{figure*}[!t]
%\rule{8.5cm}{0.37pt}
\begin{minipage}[t]{0.24\linewidth}
{\small
%\begin{Verbatim}[fontfamily=tt,frame=single]
\begin{Verbatim}
/*********** NESC ***********/
event void Boot.booted () {
  call T1.startOneShot(0);
  call T2.startOneShot(60000);
}
event void T1.fired () {
  static int on = 0;
  if (on) {
    call Leds.led0Off();
    call T1.startOneShot(2000);
  } else {
    call Leds.led0On();
    call T1.startOneShot(1000);
  }
  on = !on;
}
event void T2.fired () {
  call T1.cancel();
  call Leds.led0Off();
  <...> // CONTINUE
}
\end{Verbatim}
}
\end{minipage}
%
\hfill \vrule \hfill
\hspace{0.0cm}
%
\begin{minipage}[t]{0.28\linewidth}
%\fbox{
{\small
\begin{verbatim}
/********* PROTOTHREADS *********/
int main () {
  timer_set(&timeout, 60000);
  PT_INIT(&blink);
  while (
    PT_SCHEDULE(blink()) &&
    !timer_expired(timeout)
  );
  leds_off(LEDS_RED);
  <...> // CONTINUE
}
PT_THREAD blink () {
  while (1) {
    leds_on(LEDS_RED);
    timer_set(&timer, 2000);
    PT_WAIT_UNTIL(expired(&timer));
    leds_off(LEDS_RED);
    timer_set(&timer, 1000);
    PT_WAIT_UNTIL(expired(&timer));
  }
}
\end{verbatim}
%}
}
\end{minipage}
%
\hfill \vrule \hfill
\hspace{0.0cm}
%
\begin{minipage}[t]{0.18\linewidth}
%\fbox{
{\small
\begin{verbatim}
/******** CEU ********/
par/or do
   loop do
      _Leds_led0On();
      await 2s;
      _Leds_led0Off();
      await 1s;
   end
with
   await 1min;
end
_Leds_led0Off();
<...> // CONTINUE
\end{verbatim}
%}
}
\end{minipage}
%
\hfill \vrule \hfill
\hspace{0.0cm}
%
\begin{minipage}[t]{0.15\linewidth}
\vspace{0pt}
\centering
\includegraphics[scale=0.45]{dia.png}
\end{minipage}
%
\hspace{0.0cm}
%
\rule{18cm}{0.37pt}
\caption{ ``Blinking LED'' in
    nesC~\cite{wsn.nesc},
    Protothreads~\cite{wsn.protothreads},
    and \CEU.
    (TODO: point (1..4) in the impls.)
\label{lst.all}
}
\end{figure*}

In this work, we present the design of \CEU%
\footnote{C\'eu is the Portuguese word for \emph{sky}.},
a synchronous system-level programming language that provides a reliable yet 
powerful set of abstractions for the development of control-intensive WSNs 
applications.
%
\CEU is based on Esterel~\cite{esterel.ieee91} and introduces the following new 
safety mechanisms:
\emph{first-class timers} to ensure that timers started in parallel remain 
synchronized (not depending on internal reaction timings);
\emph{finalization blocks} for local pointers going out of scope;
and a \emph{stack-based event-driven communication} that avoids cyclic 
dependencies.
%
Our overall contribution is a static analysis that considers all language 
mechanisms and detects safety threats at compile time, such as concurrent 
accesses to shared memory, and concurrent termination of timers and threads.
%
Currently, we focus only on \emph{concurrency safety}, rather than on 
\emph{type safety}~\cite{wsn.safety}.%
\footnote{
We consider both safety aspects to be complimentary and orthogonal, i.e., 
type-safety annotations could also be applied to \CEU.
}

As a inherent limitation of \CEU's synchronous model, computations that run in 
unbounded time (e.g., compression, image processing) do not fit the zero-delay 
reaction hypothesis~\cite{rp.hypothesis}, and cannot be elegantly implemented.
%
Also, the static analysis precludes any dynamic support in the language, such 
as memory allocation and dynamic loading.
%
That said, we re-implemented in \CEU the \emph{CC2420} radio driver, and the 
\emph{DRIP}, \emph{SRP}, and \emph{CTP} network protocols~\cite{wsn.teps}.
% (all originally implemented in \emph{nesC}~\cite{wsn.teps}).
Our evaluation shows that the expressiveness of \CEU is not only sufficient for 
the context of WSNs, but actually reduced the code complexity in 25\%, with an 
increase in ROM and RAM consumption below 10\% in comparison to 
\emph{nesC}~\cite{wsn.nesc}.
%The radio driver also shows a responsiveness equivalent to \emph{nesC} in most 
%scenarios.

The rest of the paper is organized as follows:
Section~\ref{sec.overview} gives an overview of how different programming 
models used in WSNs can express typical control patterns.
Section~\ref{sec.ceu} details the design of \CEU, motivating and discussing the
safety aspects of each relevant language feature.
Section~\ref{sec.eval}, evaluates the implementation of the network protocols 
in \CEU and compares some aspects with \emph{nesC} (e.g. memory usage and 
tokens count).
We also evaluate the responsiveness of the radio driver written in \CEU.
Section~\ref{sec.related} discusses related work to \CEU.
Section~\ref{sec.conclusion} concludes the paper and makes final remarks.

\section{Overview of programming models}
\label{sec.overview}

As briefly introduced, WSNs applications must handle a multitude of concurrent 
events, such as from timers and packet transmissions.
Although they may seem random and unrelated for an external observer, a
program must keep track of them in a logical fashion, in accordance with its 
specification.
%
From a control perspective, the logical relations among events follow two main 
patterns: \emph{sequential}, i.e., program activities composed of two or more 
states in sequence; or \emph{parallel}, i.e., unrelated activities that 
eventually need to synchronize.
%
As an example, an application that alternates between sampling a sensor and 
broadcasting its readings has a clear sequential pattern (with an enclosing 
loop); while including an 1-minute timeout to interrupt the activity consists 
of a parallel pattern.

Figure~\ref{lst.all} exposes the different programming models used in WSNs, 
showing three implementations for an application that continuously lights on a 
LED for 2 seconds and off for 1 second.
After 1 minute, the application turns off the LED and proceeds to the code 
marked as \code{<...>}.
The diagram on the right describes the overall control behavior for the 
application.
The sequential pattern is represented with the LED alternating between the two 
states, while the parallel pattern is represented by the 1-minute timeout.
% that interrupts the blinking LED.

The first implementation, which represents the \emph{event-driven} 
model~\cite{wsn.nesc,wsn.contiki}, spawns two timers at boot time 
(\code{Boot.booted}), one to blink the LED and another to wait for 1 minute.
The callback \code{T1.fired} continuously toggles the LED and resets the timer 
according to the state variable \code{on}.
The callback \code{T2.fired} executes once, cancelling the blinking timer and 
proceeding to \code{<...>}.
This implementation has little structure, given that the blinking loop is not 
explicit, but instead, relies on a static state variable and multiple 
invocations of the same callback.
Furthermore, the timeout handler needs specific knowledge about how to stop the 
blinking activity manually (\code{T1.cancel()}).

The second implementation, which represents the \emph{multi-threaded} 
model~\cite{wsn.protothreads,wsn.mantisos}, uses a dedicated thread to blink 
the LED in a loop, bringing more structure to the solution.
The main thread also helps identifying the overall sequence of the program, 
which is not easily identifiable in the event-driven implementation without 
tracking the dependencies among callbacks.
However, it still requires a lot of bookkeeping for initializing, scheduling 
and rejoining the blinking thread after the timeout.

% ASYNC MT?

The third implementation, in \CEU, which represents the \emph{synchronous 
model}, uses a \code{par/or} construct to run the two activities in parallel:
an endless loop to blink the LED, and a single statement that waits for 1 
minute before terminating.
A \code{par/or} stands for \emph{parallel or} and rejoins automatically when 
any of its trails terminates.
(\CEU also supports \code{par/and} compositions, which rejoin when \emph{all} 
spawned trails terminate.)
%
The hierarchical structure of \CEU more closely reflects the diagram and ties 
the two activities together, implying that
(a) they can only exist together;
(b) they always start together
(c) they always terminate together.
%
Besides the arguably cleaner syntax, the additional control-flow information 
provided in the program is the base for all features and safety guarantees 
introduced by \CEU.

% TODO
%The challenge is how to provide a design that embraces/xxx safety/determinism, 
%specially considering pointers

%\afterpage{clearpage}
\section{The design of C\'eu}
\label{sec.ceu}

\CEU{} is a concurrent language in which multiple lines of execution (known as 
\emph{trails}) continuously react to input events from the environment.
Waiting for an event halts the running trail until that event occurs.
The environment broadcasts occurring events to all active trails, which share a 
single global time reference (an event itself).
%
%\subsection{Parallel syntactic compositions}
%\label{sec.ceu.par}
%
The fundamental distinction between \CEU and prevailing multi-threaded designs 
is the way threads are combined in programs.
\CEU provides Esterel-like syntactic hierarchical compositions, while 
conventional multi-threaded systems typically only support top-level 
definitions for threads.

The example in Figure~\ref{lst.radio} is extracted from our port of the 
\emph{CC2420} radio driver~\cite{wsn.teps} to \CEU and uses a \code{par/or} to 
control the start/stop behavior of the radio.
The input events \code{CC2420\_START} and \code{CC2420\_STOP} (line 1) 
represent the external interface of the driver with a client application (e.g.  
a protocol).
The driver enters the top-level loop (lines 2-11) and awaits the starting event 
(line 3);
upon request, the driver spawns two other trails:
one to await the stopping event (line 5),
and another to actually receive radio messages in a loop (collapsed in line 9).
%
\begin{figure}[t]
%\rule{8.5cm}{0.37pt}
{\small
\begin{verbatim}
 1:    input void CC2420_START, CC2420_STOP;
 2:    loop do
 3:        await CC2420_START;
 4:        par/or do
 5:            await CC2420_STOP;
 6:        with
 7:            // loop with other nested trails
 8:            // to receive radio packets
 9:            <...>
10:        end
11:    end
\end{verbatim}
}%
\rule{8.5cm}{0.37pt}
\caption{ Start/stop behavior for the radio driver.
\label{lst.radio}
}
\end{figure}
%
As compositions can be nested, the receiving loop can be as complex as needed, 
but once an external request to stop the driver is triggered, the \code{par/or} 
composition kills all nested trails and proceeds to the statement in sequence.
In this case, the top-level loop restarts, waiting again for the start event.

The \code{par/or} construct is regarded as an \emph{orthogonal preemption 
primitive}~\cite{esterel.preemption} because the two sides in the composition 
need not to be tweaked with synchronization primitives or state variables in
order to be affected by the other side in parallel.
It is known that traditional multi-threaded languages cannot express thread 
termination safely~\cite{esterel.preemption,sync_async.threadsstop}, thus being 
incompatible with a \code{par/or} construct.

\begin{comment}
The same start/stop control pattern for the radio driver appears in all ported 
network protocols presented in Section~\ref{sec.eval}.
In practical terms, parallel compositions eliminated all state variables in our 
ports, not only those related to split-phase 
operations~\cite{wsn.protothreads}.
\end{comment}

\subsection{Deterministic and bounded execution}
\label{sec.ceu.det}

% TODO: motivate?

\CEU{} is grounded on a precise definition of time as a discrete sequence of 
external input events:
% \footnote{We use the terms \emph{external input event}, \emph{external event}, 
%and \emph{input event} interchangeably.}
a sequence because only a single input event is handled at a time; discrete 
because a complete reaction always executes in bounded time (to be discussed 
further).
The execution model for a \CEU{} program is as follows:

\begin{enumerate}
\item The program initiates the ``boot reaction'' in a single trail.
\item Active trails execute until they await or terminate.
      This step is named a \emph{reaction chain}, and always runs in bounded 
      time.
\item The program goes idle and the environment takes control.
\item On the occurrence of a new external input event, the environment awakes 
      \emph{all} trails awaiting that event.
      It then goes to step 2.
\end{enumerate}

% TODO
The synchronous model is based on the hypothesis that internal reactions run 
\emph{infinitely faster} than the rate of events from the 
environment~\cite{rp.hypothesis}.
Conceptually, a program takes no time on step 2 and is always idle on step 3.
In practice, if a new external input event occurs while a reaction chain is 
running (step 2), it is enqueued to run in the next reaction.
%, because reaction chains must run to completion.
%
% TODO: a similar approach is taken in \cite{...}
%
When multiple trails are active at a time (i.e. awaking from the same event), 
\CEU schedules them in the order they appear in the program text.
This policy is somewhat arbitrary, but provides a priority scheme for trails, 
and also ensures a deterministic and reproducible execution for programs.

The blinking LED example of Figure~\ref{lst.all} illustrates how the 
synchronous model leads to a simpler reasoning about concurrency aspects.
As reaction times are assumed to be instantaneous, the blinking loop takes 
exactly 3 seconds.
Hence, after 20 iterations, the accumulated time becomes 1 minute and the loop 
terminates concurrently with the 1-minute timeout in parallel.
Given that the blinking trail appears first, the loop restarts and turns on the 
LED for the last time.
Then, the 1-minute timeout is scheduled, kills the whole \code{par/or}, and 
turns off the LED.
%
This reasoning is reproducible in practice, and the LED will light on exactly 
21 times for every execution of this program.
First-class timers are discussed in more depth in 
Section~\ref{sec.ceu.wclocks}.
%
Note that this static inference cannot be easily extracted from the other 
implementations of Figure~\ref{lst.all}, specially considering the presence of 
timers.

The described behavior for the last iteration of the loop is known as 
\emph{weak abortion}, because the blinking trail had the chance to execute for 
the last time.
By inverting the two trails, the \code{par/or} would terminate immediately, and 
the blinking trail would not execute, qualifying a \emph{strong 
abortion}~\cite{esterel.preemption}.
%
\CEU not only provides means to choose between weak and strong abortion, but 
also detects the two conflicting possibilities and issues a warning at compile 
time (to be discussed in Section~\ref{sec.ceu.shared}).

Reactions to the environment should run in bounded time to guarantee that 
programs are responsive and can handle upcoming input events.
Similarly to Esterel~\cite{esterel.ieee91}, \CEU requires that each possible 
path in a loop body contains at least one \code{await} or \code{break} 
statement, thus ensuring that loops never run in unbounded time.
%
Consider the examples that follow:

{\small
\begin{verbatim}
    loop do                     loop do
        if <cond> then              if <cond> then
            break;                      break;
        end                         else
    end                                 await A;
                                    end
                                end
\end{verbatim}
}

The first example is refused at compile time, because the \code{if} true branch 
may never execute, resulting in a \emph{tight loop} (i.e., an infinite loop 
that does not await).
The second variation is accepted, because for every iteration, the loop either 
breaks or awaits.

Enforcing bounded execution makes \CEU inappropriate for algorithmic-intensive 
applications that require unrestricted loops (e.g., cryptography, image 
processing).
However, \CEU is designed for control-intensive applications and we believe 
this is a reasonable price to pay in order to achieve higher reliability.

% TODO: pause

\subsection{Shared-memory concurrency}
\label{sec.ceu.shared}

WSNs applications make extensive use of shared memory, such as for handling 
memory pools, message queues, routing tables, etc.
Hence, an important goal of \CEU is to ensure a reliable execution for 
concurrent programs that share memory.

Concurrency in \CEU is characterized when two or more trails segments execute 
during the same reaction chain.
A trail segment is a sequence of statements separated by an \code{await}.

In the first example that follows, the assignments run concurrently, because 
both trail segments are spawned during the same reaction chain.
However, in the second example, the assignments are never concurrent, because 
$A$ and $B$ represent different external events and the respective segments can 
never execute during the same reaction chain:

\begin{minipage}[t]{0.40\linewidth}
{\small
\begin{verbatim}
var int v=0;
par/and do
    v = v + 1;
with
    v = v * 2;
end
\end{verbatim}
}
\end{minipage}
\hspace{0cm}
\begin{minipage}[t]{0.40\linewidth}
{\small
\begin{verbatim}
input void A, B;
var int v=0;
par/and do
    await A;
    v = v + 1;
with
    await B;
    v = v * 2;
end

\end{verbatim}
}
\end{minipage}

Note that although variable $v$ is accessed concurrently in the first example, 
the assignments are both atomic and deterministic (given the run to completion 
semantics and the scheduling policy): the final value of $v$ is always $2$.
%
However, programs with concurrent accesses to shared memory are suspicious, 
because an apparently innocuous reordering of trails modifies the semantics of 
the program.

%Moreover, \CEU also supports pointers, which are required for low-level 
%manipulation (e.g., accessing buffers from device drivers).

We developed a compile-time temporal analysis for \CEU in order to detect 
concurrent accesses to shared variables, as follows:
\emph{if a variable is written in a trail segment, then a concurrent trail 
segment cannot read or write to that variable, nor dereference a pointer of 
that variable type.}
An analogous policy is applied for pointers vs variables and pointers vs 
pointers.
For each variable access, the analysis algorithm holds the set of all possible 
preceding \code{await} statements.
Then, the sets for all accesses in parallel trails are compared to assert that 
no \code{await} statements are shared.
Otherwise the compiler warns about the suspicious accesses.

Consider the three examples of Figure~\ref{lst.det}.
The first code is detected as suspicious, given that both assignments may be 
concurrent in a reaction to $A$ (lines 11 and 14);
In the second code, although two of the assignments occur in reactions to $A$ 
(lines 5 and 11), they are not in parallel trails and, hence, are safe.
The third code illustrates a false positive in our algorithm, as the 
assignments in parallel can only occur in different reactions to $A$ (lines 5 
and 9).

\begin{figure}[t]
\begin{minipage}[t]{0.05\linewidth}
{\small
\begin{verbatim}
 1:
 2:
 3:
 4:
 5:
 6:
 7:
 8:
 9:
10:
11:
12:
13:
14:
15:
\end{verbatim}
}
\end{minipage}
\hspace{0cm}
\begin{minipage}[t]{0.32\linewidth}
{\small
\begin{verbatim}
input void A;
var int v;
var int* p;
par/or do
  loop do
    await A;
    if <cnd> then
      break;
    end
  end
  v = 1;
with
  await A;
  *p = 2;
end
\end{verbatim}
}
\end{minipage}
\hspace{0cm}
\begin{minipage}[t]{0.29\linewidth}
{\small
\begin{verbatim}
input void A, B;
var int v;
par/or do
  await A;
  v = 1;
with
  await B;
  v = 2;
end
await A;
v = 3;
\end{verbatim}
}
\end{minipage}
\hspace{0cm}
\begin{minipage}[t]{0.25\linewidth}
{\small
\begin{verbatim}
input void A;
var int v;
par/and do
  await A;
  v = 1;
with
  await A;
  await A;
  v = 2;
end
\end{verbatim}
}
\end{minipage}
\rule{8.5cm}{0.37pt}
\caption{ The first and third programs are suspicious.
\label{lst.det}
}
\end{figure}

Weak and strong abortions, as presented in Section~\ref{sec.ceu.det}, are also 
detected with the proposed algorithm.
Instead of accesses to variables, the algorithm asserts that no join points of 
a \code{par/or} execute concurrently with a nested trail in parallel, issuing a 
warning otherwise.

The proposed static analysis is only possible due to syntactic compositions, 
which provide precise information about the flow of trails, i.e., which run in 
parallel and which are guaranteed to be in sequence.
Such information cannot be inferred when the program control relies on state 
variables.

We also implemented an alternative algorithm that converts a \CEU program into 
a deterministic finite automata.
The resulting DFA represents all possible points a program can reach during 
runtime and, hence, eliminates all false positives.
However, the algorithm is exponential and may be impractical in some 
situations.
%
That said, the simpler static analysis executes in negligible time for all 
implementations to be presented in Section~\ref{sec.eval} and does not detect 
any false positives, suggesting that the algorithm is practical.

\subsection{Integration with $C$}
\label{sec.ceu.c}

Most existing operating systems, programming languages, and libraries for WSNs 
rely on $C$, given its omnipresence and level of portability across embedded 
platforms.
This way, it is fundamental that programs in \CEU have access to all 
functionality the underlying platform already provides.

In \CEU, any identifier prefixed with an underscore is repassed \emph{as is} to 
the $C$ compiler that generates the final binary.
This way, access to $C$ is seamless and, more importantly, easily trackable.
%
\CEU also supports \emph{C~blocks} to define new symbols, as Figure~\ref{lst.c} 
illustrates.
All code inside ``\code{C do ... end}'' is also repassed to the $C$ compiler 
for the final generation phase.
%Only global definitions are allowed inside $C$ blocks.
Note that \CEU{} mimics the type system of $C$, so that values can be 
seamlessly passed back and forth between the languages.

% TODO: real example?
\begin{figure}[t]
%\rule{8.5cm}{0.37pt}
{\small
\begin{verbatim}
   C do
       #include <assert.h>
       int I = 0;
       int inc (int i) {
           return I+i;
       }
   end
   C _assert(), _inc(), _I;
   return _assert(_inc(_I));
\end{verbatim}
}
\rule{8.5cm}{0.37pt}
\caption{ A \CEU program with embedded $C$ definitions.
\label{lst.c}
}
\end{figure}

$C$ calls are fully integrated with the static analysis presented in
Section~\ref{sec.ceu.det} and cannot appear in concurrent trails segments, 
given that \CEU has no knowledge about their side effects.
Also, passing variables as parameters counts as read accesses to them, while 
passing pointers counts as write accesses to those types (because functions may 
dereference and assign to them).
%
This policy increases considerably the number of false positives in the 
analysis, given that many functions can actually be safely called concurrently.
Therefore, \CEU supports syntactic annotations to relax the policy explicitly:

\begin{itemize}
\item The \code{pure} modifier declares a $C$ function that does not cause side 
      effects, allowing it to be called concurrently with any other function in 
the program.
\item The \code{deterministic} modifier declares a pair of variables or 
      functions that do not affect each other, allowing them to be used 
concurrently.
\end{itemize}

The following code illustrates \CEU annotations:

% TODO: exs from ports

{\small
\begin{verbatim}
    pure  _abs();      // 'abs' is side-effect free
    deterministic      // 'led0Toggle' vs 'led1Toggle' is safe
        _Leds_led0Toggle with _Leds_led1Toggle;
    int*  buf1, buf2;  // point to different buffers
    deterministic      // 'buf1' vs 'buf2' is safe
        buf1 with buf2;
\end{verbatim}
}

\begin{comment}
TODO

Annotations are typically write-once declarations (when integrating a $C$ 
service for the first time) to be included in actual applications.
Note that the example in Figure~\ref{lst.blink} should include the annotation 
for \code{\_Leds\_led0Toggle} and \code{\_Leds\_led1Toggle} above to be 
compiled correctly.
\end{comment}

\CEU does not extend the bounded execution analysis to $C$ function calls. 
% which are left as responsibility for the programmer.
% TODO: other languages dont as well
On the one hand, $C$ calls must be carefully analyzed in order to keep programs 
responsive.
On the other hand, they also provide means to circumvent the rigor of \CEU in a 
well-marked way (the special underscore syntax).
%
\begin{comment}
This approach is also adopted by Esterel, which supports the \code{call} 
primitive to execute code assumed to be instantaneous in the host 
language~\cite{esterel.primer}.
In \CEU, we take a step further and statically detects when such calls may 
execute concurrently, as discussed in the next section.
\end{comment}
%
Evidently, programs should only recur to $C$ for I/O operations that are 
assumed to be instantaneous, but never for control purposes.
% (e.g. interrupt handling).

\subsection{Local scopes and finalization}
\label{sec.ceu.fins}

\begin{figure}[t]
%\rule{8.5cm}{0.37pt}
{\small
\begin{verbatim}
 1:  <...>
 2:  par/or do
 3:      <...>           // stop the protocol or radio
 4:  with
 5:      <...>           // neighbour request
 6:  with
 7:      loop do
 8:          par/or do
 9:              <...>   // resend request
10:          with
11:              await (dt) ms;  // beacon timer expired
12:              var _message_t msg;
13:              payload = _AMSend_getPayload(&msg, ...);
14:              <prepare the message>
15:              _AMSend_send(..., &msg, ...);
16:              await CTP_ROUTE_RADIO_SENDDONE;
17:          end
18:      end
19:  end
\end{verbatim}
}
\rule{8.5cm}{0.37pt}
\caption{ Unsafe use of local references.
\label{lst.local}
}
\end{figure}

Local declarations for variables bring definitions closer to their use in 
programs, increasing the readability and containment of code.
Another benefit, specially in the context of WSNs, is that blocks in sequence 
can share the same memory space, given that they are never active at the same 
time.

The syntactic compositions of trails allows the \CEU compiler to statically 
allocate and optimize memory usage~\cite{wsn.osm}:
memory for trails in parallel must coexist;
trails that follow rejoin points reuse all memory.

However, the unrestricted use of locals introduce subtle bugs when dealing with 
pointers and $C$ functions.
Given that global $C$ functions outlive the scope of locals, a pointer passed 
as parameter may be used after the referred variable goes out of scope, leading 
to a dangling pointer.

The code snippet in Figure~\ref{lst.local} was extracted from our port of the 
CTP collection protocol~\cite{wsn.teps} to \CEU.
The protocol contains a complex control hierarchy in which the trail that sends 
beacon frames may be killed or restarted from multiple sources (protocol/radio 
stop, and local/network resend request, all collapsed in lines 3, 5, and 9).

The sending loop (lines 7-18) awakes when the beacon timer expires (line 11).
The message buffer is declared only where it is required (line 12, in the 6th 
depth-level of the program), but its reference is manipulated by two $TinyOS$ 
global functions:
\code{AMSend\_getPayload} (line 13), which gets the data region of the message 
to be prepared (collapsed in line 14);
and \code{AMSend\_send} (line 15), which requests the operating system to 
actually send the message.
As the radio driver runs asynchronously and holds a reference to the message 
until it is completely transmitted, the sending trail may be killed in the 
meantime, resulting in a dangling pointer in the program.
%
A possible solution is to include a call to \code{AMSend\_cancel} in all trails 
that kill the sending trail.
However, this would require to expand the scope of the message buffer and add a 
state variable to keep track of the sending status, increasing considerably the 
complexity of the application.

\CEU provides a safer and simpler solution with the following rule:
\emph{$C$ calls that receive pointers require a finalization block to safely 
handle referred variables going out of scope}.
This rule prevents the previous example to compile, forcing the relevant parts 
to be be rewritten as

{\small
\begin{verbatim}
    C nohold _AMSend_getPayload();
        <...>
            var _message_t msg;
            <...>
            finalize
                _AMSend_send(..., &msg, ...);
            with
                _AMSend_cancel(&msg);
            end
        <...>
\end{verbatim}
}

First, the \code{nohold} annotation informs the compiler that the referred $C$ 
function does not require finalization code because it does not hold 
references.
Second, the \code{finalize} construct automatically executes the \code{with} 
clause when the variable passed as parameter in the \code{finalize} clause goes 
out of scope.
This way, regardless of how the sending loop is killed, the finalization code 
politely requests the OS to cancel the ongoing send operation.

\begin{comment}
% TODO: expand
During the porting process, we identified two potentially harmful system calls 
that require

The send/cancel pattern occurs in all ported applications that use the radio 
for communication evaluated in Section~\ref{sec.eval}.

 that  two dangerous

given that the porting process was straghtforward, we believe that the 
\emph{nesC} implementation is free of such ...
However, .
performance degradation
another endorsement

- exception srp queue
we know exactly the place where it occurs
nesC no

* cancel
* timers
* locals

%TODO: LOCALS AND PAR COMPOSITIONS ARE A PERFECT MATCH

As a final consideration, we propose to extend the idea of compositions by 
combining different \emph{applications} together.
In the context of WSNs, it is usually difficult to physically recover motes in 
a deployed network, and by combining multiple applications in a single image, 
we can switch their execution remotely via radio.
The following archetype illustrates this idea:

{\small
\begin{verbatim}
     1:   input int SWITCH;
     2:   var int app = 1;
     3:   loop do
     4:      par/or do
     5:         app = await SWITCH;
     6:      with
     7:         if app == 1 then
     8:            <CODE for APP1>
     9:         else/if app == 2 then
    10:            <CODE for APP2>
    11:         end
    12:         await FOREVER;
    13:      end
    14:   end
\end{verbatim}
}

The input event \code{SWITCH} (line 1) is used to request application switches 
remotely.%
\footnote{ We are assuming the existence of an hypothetical high-level event 
\code{Switch} that abstracts the radio protocol for requests to change the 
current running application. }
Initially, the code behaves as application $1$ (lines 7-9), but is also waiting 
for a \code{Switch} request in parallel (line 5).
Whenever a new request occurs, the \code{par/or} terminates, kills the running 
application, and restarts as the requested application.
The \code{await Forever} statement (line 13) ensures that a terminating 
application does not restart itself.

The same idea can be used to \emph{reboot} a mote remotely, in the case of a 
strange behavior in an application.
\end{comment}

\subsection{Wall-clock time}
\label{sec.ceu.wclocks}

% TODO: ana

Activities that involve reactions to \emph{wall-clock time}%
\footnote{
By wall-clock time we mean the passage of time from the real world, measured in 
hours, minutes, etc.
}
appear in typical patterns of WSNs, such as sensor sampling and activity 
timeouts.
However, support for wall-clock time is somewhat low-level in existing 
languages, usually through timer callbacks or sleep blocking calls.
%
In any concrete system implementation, a requested timeout does not expire 
precisely with zero-delay, a fact that is usually ignored in the development 
process.
We define the difference between the requested timeout and the actual expiring 
time as the \emph{residual delta time (delta)}.
Without explicit manipulation, the recurrent use of timed activities in 
sequence (or in a loop) might accumulate a considerable amount of deltas that 
could lead to incorrect behavior in programs.

The \code{await} statement of \CEU supports wall-clock time and handles deltas 
automatically, resulting in more robust applications.
As an example, consider the following program:

{\small
\begin{verbatim}
    int v;
    await 10ms;
    v = 1;
    await 1ms;
    v = 2;
\end{verbatim}
}

Suppose that after the first \code{await} request, the underlying system gets 
busy and takes 15ms to check for expiring awaits.
The \CEU scheduler will notice that the \code{await 10ms} has not only already 
expired, but delayed with \code{delta=5ms}.
Then, the awaiting trail awakes, sets \code{v=1}, and invokes \code{await 1ms}.
However, the current delta is higher than the requested timeout (i.e. $5ms > 
1ms$), so the trail is immediately rescheduled for execution, now with 
\code{delta=4ms}.

\CEU also takes into account the fact that time is a physical quantity that can 
be added and compared.
For instance, for the program that follows, although the scheduler cannot 
guarantee that the first trail terminates exactly in 11ms, it can at least 
ensure that the program always returns $1$:

%\begin{figure}[t]
%\rule{8.5cm}{0.37pt}
{\small
\begin{verbatim}
    par do
        await 10ms;
        <...>         // any non-awaiting sequence
        await  1ms;
        return 1;
    with
        await 12ms;
        return 2;
    end
\end{verbatim}
}
%\rule{8.5cm}{0.37pt}
%\caption{ The first trail always terminates the program.
%\label{lst.time}
%}
%\end{figure}

Remember that any non-awaiting sequence is considered to take no time in the 
synchronous model.
Hence, the first trail is guaranteed to terminate before the second trail, 
because $10+1 < 12$.
A similar program in a language without first-class support for timers, would 
depend on the execution timings for the code marked as \code{<...>}, making the 
reasoning about the execution behavior more difficult.

% TODO: uses in ports
% trickle?

\subsection{Internal events}
\label{sec.ceu.ints}

\begin{figure}[t]
%\rule{8.5cm}{0.37pt}
{\small
\begin{verbatim}
event int send;
par do
    <...>
        await DRIP_KEY;
        emit send=0;        // broadcast data
with
    <...>
        await DRIP_TRICKLE;
        emit send=1;        // broadcast meta
with
    <...>
        var _message_t* msg = await DRIP_DATA_RECEIVE;
        <...>
        emit send=0;        // broadcast data
with
    loop do
        var int isMeta = await send;
        <...>   // send data or metadata
    end
end
\end{verbatim}
}
\rule{8.5cm}{0.37pt}
\caption{ The \code{send} ``subroutine'' is invoked from different parts of the 
program.
\label{lst.func}
}
\end{figure}

% TODO: ana

\CEU provides internal events as a signaling mechanism among trails in 
parallel:
a trail that invokes \code{await~e} can be awaken in the future by a trail that 
invokes \code{emit~e}.

In contrast with external events, which are handled in a queue, internal events 
follow a stack policy.
In practical terms, this means that a trail that emits an internal event pauses 
until all trails awaiting that event completely react to it, continuing to 
execute afterwards.
%
Another difference to external events is that internal events occur in the same 
reaction chain they are emitted, i.e., an \code{emit} instantaneously matches 
and awakes all correspondent \code{await} statements that were invoked in 
\emph{previous reaction chains}.
In order to ensure bounded execution, an \code{await} statement cannot awake on 
the same reaction chain it is invoked.

The stacked execution for internal events introduces support for a restricted 
form of subroutines that cannot express recursive definitions (either directly 
or indirectly), resulting in bounded memory and execution time.
% that preclude stack overflows.
% TODO: exec bounded
% TODO: why?
%
Figure~\ref{lst.func} shows how the dissemination trail from our port of the 
DRIP protocol to \CEU can be invoked from different parts of the program, just 
like subroutines.
The DRIP protocol distinguishes from data and metadata packets and disseminates 
one or the other based on external requests.
For instance, when the trickle timer expires, the program invokes 
\code{emit~send=1}, which awakes the dissemination trail and starts sending a 
metadata packet.
If the trail is already sending a packet, than the \code{emit} does not match 
the \code{await} and will have no effect (just like the \emph{nesC} 
implementation, which uses a explicit state variable to achieve this behavior).

% TODO: missed sends / non reentrancy

Internal events also provide means for describing more elaborate control 
structures, such as \emph{exceptions}.
The code in Figure~\ref{lst.exception} handles incoming packets for the CC2420 
radio driver in a loop (lines 3-17).
After awaking from a new packet notification (line 4), the program enters in a 
sequence to read the bytes from the hardware buffer (lines 8-17).
If any anomaly is found on the received data, the program invokes 
\code{emit~next} to discard the current packet (lines 10,14).
Given the execution semantics of internal events, the \code{emit} continuation 
is stacked and awakes the trail in line 6, which terminates and kills the whole 
\code{par/or} in which the emitting trail is paused.
This way, the continuation for the \code{emit} never resumes, and the loop 
restarts to await the next packet.

% TODO: resumable

\begin{figure}[t]
%\rule{8.5cm}{0.37pt}
{\small
\begin{verbatim}
 1:    <...>
 2:    event void next;
 3:    loop do
 4:        await CC_RECV_FIFOP;
 5:        par/or do
 6:            await next;
 7:        with
 8:            <...>
 9:            if rxFrameLength > _MAC_PACKET_SIZE then
10:                emit next;  // packet is too large
11:            end
12:            <...>
13:            if rxFrameLength == 0 then
14:                emit next;  // packet is empty
15:            end
16:            <...>
17:        end
18:    end
\end{verbatim}
}
\rule{8.5cm}{0.37pt}
\caption{ The \code{emit} raises an exception caught by the \code{await}.
\label{lst.exception}
}
\end{figure}

% TODO
%\subsection{Limitations}
%\subsection{Implementation}

%\newpage
\section{Evaluation}
\label{sec.eval}

\begin{figure*}[t]
\includegraphics[width=\textwidth]{eval.png}
\caption{ Comparison between \CEU and \emph{nesC} for the ported applications.
\label{fig.eval}
}
\end{figure*}

In order to evaluate the applicability of \CEU in the context of WSNs, we 
re-implemented a number of protocols and system utilities originally written in 
\emph{nesC}~\cite{wsn.nesc} from the TinyOS operating system~\cite{wsn.tos}.
%
We chose \emph{nesC} in our evaluation given its resource efficiency, code base 
maturity, and because it is used as benchmark in many related works to \CEU 
(e.g.  \cite{wsn.protothreads,wsn.sol,wsn.ocram,wsn.flowtalk}).

% TODO: our git

Our evaluation consists of the following implementations:
the \emph{Trickle} timer;
the receiving component of the \emph{CC2420} radio driver;
the \emph{DRIP} dissemination protocol;
the \emph{SRP} routing protocol;
and the routing component of the \emph{CTP} collection protocol.
%
They represent well the realm of system-level development for WSNs, which 
mostly consists of network protocols and lower level utilities to be used as 
services in applications.
They are also intensive in control and concurrency aspects, being perfect 
targets to \CEU.
Finally, they are open standards~\cite{wsn.teps}, with open implementations%
\footnoteremember{tos}
    {TinyOS repository: \url{github.com/tinyos/tinyos-release}},
and are academically recognized~\cite{wsn.trickle,wsn.ctp}.

% TODO
% \footnote{The source code for both \CEU and \emph{nesC} can be found at
% \url{github.com/xxx/}.}:

We took advantage of the component-based model of TinyOS and all of our ports 
use the same interface provided by the \emph{nesC} counterpart---
changing from one implementation to the other is done by swapping a single 
file.
This way, we could use existing test applications available in the TinyOS 
repository (e.g. \emph{RadioCountToLeds} and 
\emph{TestNetwork}~\footnoterecall{tos}).
%we could retain the same architecture between the implementations, making 
%easier to mimic \emph{nesC}'s functionality.

Figure~\ref{fig.eval} shows the comparison for \emph{resource usage} and 
\emph{code complexity} between \emph{nesC} and \CEU, which are discussed in
Sections~\ref{sec.eval.resource}~and~\ref{sec.eval.code}, respectively.
The figure also details how many times each relevant feature of \CEU was used 
in the implementations (i.e., local variables, internal events, first-class 
timers, parallel compositions, and maximum number of concurrent trails).

We also evaluate the performance of \CEU with respect to responsiveness, i.e., 
its capacity to promptly acknowledge requests from the environment, such as 
radio packets arrivals.
Section~\ref{sec.eval.radio} presents two experiments that measure the 
responsiveness of the implemented radio driver under high loads.

\subsection{Memory usage}
\label{sec.eval.resource}

Memory is a scarce resource in WSNs motes and it is important that \CEU does 
not pose significant overheads in comparison to \emph{nesC}.
%
We evaluate ROM and RAM consumption by using the simplest available test 
applications for the ported implementation.
We tweaked each application to remove extra functionality so that the generated 
binary is dominated by the component of interest.
Them, we compiled each application twice: one with the original component in 
\emph{nesC}, and another with the ported component in \CEU.
%
Figure~\ref{sec.eval} shows in the column \emph{Memory usage} the consumption 
of ROM and RAM for the generated applications.
With the exception of the Trickle timer, the results in \CEU remains below 10\% 
in ROM and 5\% in RAM in comparison with the implementations in \emph{nesC}.
%
Our method and results are similar to those for
Protothreads~\cite{wsn.protothreads}, which is used extensively in Contiki, and 
has a simple and lightweight implementation based on a set of C macros.

The Trickle timer illustrates the footprint of the runtime of \CEU.
The RAM overhead of 20\% actually corresponds to only 16 bytes: 1 byte for each 
of the maximum 6 concurrent trails, and 10 bytes to handle synchronization 
among timers.
%
As the complexity of the application grows, this overhead tends to discharge.
%
The SRP implementation could eliminate a queue by signaling events internally, 
hence the decrease in RAM.
%
Note that both TinyOS and \CEU define functions to manipulate queues for tasks 
(or trails) and timers.
Hence, given that our implementations mix components in the two systems, we pay 
a considerable overhead in ROM.

We focused most of our implementation efforts on RAM optimization, as it has 
been historically considered more scarce then ROM~\cite{wsn.decade}.
Although, we have achieved competitive results, we expected more gains with 
memory reuse for blocks in sequence, because it is something that cannot be 
done automatically by the \emph{nesC} compiler.
However, we carefully analyzed each ported application and it turned out that 
we had no gains \emph{at all} from blocks in sequence.
Our conclusion is that sequential patterns in WSNs applications either come 
from split-phase operations, which always require to preserve memory;
or from loops, which do reuse all memory, but in the same way event-driven 
systems do.

\subsection{Code complexity}
\label{sec.eval.code}

We used two metrics to compare code complexity between the implementations in 
\CEU and \emph{nesC}: the number of tokens and the number of global variables 
used in the source code.
%
Similarly to comparisons from related works~\cite{wsn.ocram,wsn.protothreads}, 
we did not consider code shared among the implementations, as they do not 
represent control functionality and pose no challenges regarding concurrency 
aspects (i.e. they are predicates, \code{struct} accessors, etc.).

We chose to use tokens instead of lines of code because the code density is 
considerably lower in \CEU, given that most lines are composed of a single 
block delimiter from a structural composition.
%
Note that the languages share the core syntax for expressions, calls, and field 
accessors (based on $C$), and we removed all verbose annotations from the 
\emph{nesC} implementations (e.g. \code{signal}, \code{call}, \code{command}, 
etc.) for a fair comparison.
%
Figure~\ref{fig.eval} shows a considerable decrease in the number of tokens for 
all implementations (from 20\% up to 70\%).
% TODO: 20% ainda?

Globals were categorized in \emph{state} and \emph{data} variables.
%
State variables are used as a mechanism to control the application flow (on the 
lack of a better primitive).
Keeping track of them is regarded as a difficult task, hence, reduction of 
state variables has already been proposed as a metric of code complexity in a 
related work~\cite{wsn.protothreads}.
The implementations in \CEU completely eliminated state variables, and all 
control patterns could be expressed with hierarchical compositions of 
activities.
%
Data variables in WSNs are usually used to hold message buffers and protocol 
parameters (e.g. sequence numbers, timer intervals, etc.).
In event-driven systems, given that stacks are not retained across reactions to 
the environment, all data variables must be global%
\footnote{In the case of \emph{nesC}, we refer to globals as all variables 
defined in the top-level of a component implementation block (which are visible 
to all functions inside the component).}.
Although the use of local variables does not incur in reduction of lines of 
code (or tokens), we believe that the smallest the scope of a variable, the 
more readable and less susceptible to bugs the program becomes.
%
In the \CEU implementations, most variables could be nested to a deeper scope.
The column \emph{locals} in Figure~\ref{fig.eval} shows the depth of each 
global that became a local variable in \CEU (where depth=0 is a global 
variable).

The columns below \emph{C\'eu features} in Figure~\ref{fig.eval} point out how 
many times each functionality has been used in the ports, helping on 
identifying where the reduction in complexity comes from.
%
As an example, the Trickle timer uses 2 timers and 3 parallel compositions, 
resulting in at most 6 trails active at the same time (a \code{par} may spawn 
more than 2 trails).
Six trails for such a small application is justified by its highly 
control-intensive nature, and the almost 70\% code reduction illustrates the 
huge gains with \CEU in this context.
%
%TODO: CTP c/ select

% TODO: DRIP uses trickle as a service (does not implement it)

\subsection{Responsiveness}
\label{sec.eval.radio}

A known limitation of languages with synchronous and cooperative execution is 
that they cannot meet hard real-time 
deadlines~\cite{wsn.comparison,wsn.tosthreads}.
For instance, the rigorous synchronous semantics of \CEU forbids 
non-deterministic preemption to serve high priority trails.
%
This way, the implementation of a radio driver purely in \CEU raises questions
regarding its responsiveness and we conducted two experiments in order two 
evaluate it.
%
Even though WSNs protocols are usually tolerant to faults (given the unreliable 
link), packet losses affect the network performance and cause motes to spend 
more battery.

In the first experiment%
\footnote{The experiments use the \emph{COOJA} simulator~\cite{wsn.cooja} 
running images compiled to \emph{TelosB} motes.},
we performed a stress test on the radio driver to compare its performance in 
the \CEU and \emph{nesC} implementations.
We use 10 motes that broadcast 100 consecutive messages of 20 bytes to a mote 
that runs a periodic time-consuming activity.
The receiving handler simply adds the value of each received byte to a global 
counter.
% (we set a single random byte for each message, so that the sum is always 1).
%
The sending rate of each mote is 200ms (leading to an average of 50 messages 
per second considering the 10 motes), and the activity in the receiving mote 
runs every 140ms.
We run the experiment varying the duration of the lengthy activity from 0 to 
128 milliseconds.
%
We assume that the lengthy operation is implemented directly in C and cannot be 
easily split in smaller operations (e.g. recursive 
algorithms~\cite{wsn.comparison,wsn.tosthreads}).
This way, we simulated it with a simple busy wait that will keep the driver in 
\CEU unresponsive, which is our objective.
%(given the run completion semantics of the language).
%We certified that the operation executed the same number of times in \CEU and 
%\emph{nesC} for all tests in the experiment.

Figure~\ref{fig.radio1} shows the total number of handled messages in \CEU and 
\emph{nesC} for each configuration.
%
Starting from operations that take 16ms, the performance of \CEU drops below 
5\% in comparison to \emph{nesC}.
%
Our direct interpretation is that the \CEU driver starts to become unresponsive 
when receiving messages every 20ms while executing a periodic operation of 
16ms.
The same interpretation can be done for \emph{nesC}, but considering a 64-ms 
operation, which is a similar conclusion taken from TOSThreads experiments 
(25-bytes messages every 50ms, while running a 50-ms 
operation~\cite{wsn.tosthreads}).
%
Table~\ref{tab.durs} shows the durations for some lengthy operations found in 
the literature specifically designed for WSNs.
The operations in the group with timings below 8ms could be used with real-time 
responsiveness with \CEU, considering the proposed configuration parameters.
%a 5\% decrease in performance in comparison with \emph{nesC}.

\begin{figure}[t]
\includegraphics{radio1}
\caption{ Packet receives under high-loads for \CEU and \emph{nesC}.
\label{fig.radio1}
}
\end{figure}

\begin{table}[t]
\begin{center}
\begin{tabular}{ | l | r | }
\hline
    Operation          & Duration  \\ \hline
\hline
    Block cypher~\cite{wsn.tinysec,wsn.crypto}  & 1ms           \\ \hline
    MD5 hash~\cite{wsn.crypto}                  & 3ms           \\ \hline
    Wavelet decomposition~\cite{wsn.wavelet}    & 6ms           \\ \hline
    SHA-1 hash~\cite{wsn.crypto}                & 8ms           \\ \hline
\hline
    RLE compression~\cite{wsn.compression}      & 70ms          \\ \hline
    BWT compression~\cite{wsn.compression}      & 300ms         \\ \hline
    Image processing~\cite{wsn.cyclops}         & 50--1000ms    \\ \hline
\end{tabular}
\caption{Durations for lengthy operations is WSNs.}
\label{tab.durs}
\end{center}
\end{table}

\begin{figure}[t]
\includegraphics{radio2.png}
\caption{ Packet receives under high-loads for \CEU and \emph{nesC}.
\label{fig.radio2}
}
\end{figure}

Although we did not perform specific tests to evaluate CPU usage, the first 
experiment suggests that the overhead of \CEU over \emph{nesC} is lower than 
3\%, based on the packet losses for the CPU awake full time.
For lengthy operations implemented in C, there is no overhead, as the generated 
code is the same for \CEU and \emph{nesC}.

In the second experiment, instead of running an activity in parallel, we use a 
8-ms operation in sequence with message arrivals to simulate a process that is 
tied with message handling, such as encrypting and forwarding.
We now run the experiment varying the rate in the 10 sending motes from 600ms 
to 100ms.
%
Figure~\ref{fig.radio2} shows the total number of handled messages in \CEU and 
\emph{nesC} for each configuration.
%
The last column shows the theoretical limit of 80ms, i.e., receiving a message 
every 8ms and handling it in 8ms.
%
The results show that \CEU performs equally to \emph{nesC} for a frequency up 
to 50 messages per second.

% TODO: reaction times, measure or cite?

The overall conclusion is that \CEU can be used to write system-level drivers 
if other parts of the application (also in \CEU) do not execute 
algorithmic-intensive operations.
%
\CEU performs equally in comparison to \emph{nesC} for sub-millisecond 
reactions.
%
The range between 1ms and 8ms is a ``gray area'' that offers opportunities for 
simple lengthy operations, but that also requires careful analysis and testing.
%
For operations over 8ms and under high loads, \CEU will perform considerably 
worse than \emph{nesC}.

\subsection{Discussion}

\CEU targets control-intensive applications and provides abstractions that can 
better express program flow specifications.
%
Our evaluation shows a considerable decrease in complexity that comes from 
logical compositions of trails through \code{par/or} and \code{par/and} 
constructs.
%
They handle startup and termination for trails seamlessly without extra 
programming efforts.
%
The small overhead in memory qualifies \CEU as a realistic option for 
constrained devices.

% TODO
%with overheads below 5\% and 10\%
%Some overhead in memory exists, but RAM is minimal and can be avoided XXX an 
%trackable
%inherent per-trail overhead.
%
%The overhead in ROM is below 10\% but has not .

The main aspect of \CEU is to ensure that the high degree of concurrency in 
WSNs does not pose safety threats to applications.
Restricting the expressiveness of the language enabled a broad safety analysis 
in programs at compile time.
The analysis encompasses all proposed concurrency mechanisms, such as parallel 
compositions, first-class timers, and communication via events.
As summary, the following safety properties hold for all programs that 
successfully compile in \CEU:

\begin{itemize}
\item Time-bounded reactions to the environment
        (Sections~\ref{sec.ceu.det}~and~\ref{sec.ceu.ints}).
\item Reliable weak and strong trail abortion
        (Sections~\ref{sec.ceu.det}~and~\ref{sec.ceu.shared}).
\item No concurrency in variable accesses
        (Section~\ref{sec.ceu.shared}).
\item No concurrency in system calls sharing a resource
        (Section~\ref{sec.ceu.c}).
\item Finalization for blocks going out of scope
        (Section~\ref{sec.ceu.fins}).
\item Auto-adjustment for timers in sequence
        (Section~\ref{sec.ceu.wclocks}).
\item Synchronization for timers in parallel
        (Section~\ref{sec.ceu.wclocks}).
\end{itemize}

These properties are desirable in any application and are guaranteed as 
preconditions in \CEU by design.
Ensuring or even extracting these properties from unrestricted languages is not 
possible without significant manual analysis.

Even though the achieved expressiveness and overhead of \CEU meet the 
requirements of WSNs, its design imposes two inherent limitations:
the lack of dynamic primitives that would forbid the static analysis,
and the lack of hard real-time guarantees.
%
Regarding the first limitation, dynamic features are already discouraged in the 
context of WSNs due to resource constraints.
For instance, even object-oriented languages targeting WSNs forbid dynamic 
allocation~\cite{wsn.flowtalk,wsn.virgil}.

To deal with the second limitation, which can be critical in the presence of 
lengthy computations, we can consider the following approaches:
(1) carefully measure reaction times to see if deadlines are met;
(2) manually place \code{pause} statements in tight loops;
(3) integrate \CEU with a preemptive system.
%
The second option requires rewriting the lengthy computation in \CEU with
\code{pause} statements to let other trails to be scheduled.
This option is the one recommended in many related works that provide a similar 
primitive (e.g. \code{pause}~\cite{esterel.primer}, 
\code{PT\_YIELD}~\cite{wsn.protothreads}, \code{yield}~\cite{wsn.sol}, 
\code{post}~\cite{wsn.nesc}).
%
Fortunately, \CEU and preemptive threads are not mutually exclusive, and the 
third option is appealing to be explored in a future work.
For instance, TOSThreads~\cite{wsn.tosthreads} is integrated with \emph{nesC} 
via message passing, a mechanism that is safe and matches the semantics of 
external events in \CEU.

\section{Related work}
\label{sec.related}

\begin{figure*}[t]
\includegraphics[width=\textwidth]{related.png}
\caption{ Table of features found in related work to \CEU.
(Gray background indicates where they first appeared.)
TODO CEU
\label{fig.related}
}
\end{figure*}

\CEU is strongly influenced by Esterel~\cite{esterel.ieee91} on its support for 
compositions and reactivity to events.
However, Esterel is focused on control and delegates to programmers most 
efforts to deal with data and low-level access to the underlying platform.
For instance, read/write to shared memory among threads is forbidden and 
avoiding conflicts between concurrent $C$ calls is left to 
programmers~\cite{esterel.primer}.
\CEU deals with shared memory and $C$ integration at its very core, with 
additional support for finalization, conflict annotations, and a static 
analysis that permeates all languages aspects.
This way, \CEU could not be designed easily as pure extensions to Esterel.

Figure~\ref{fig.related} presents an overview of related work to \CEU, pointing 
out support for a number of features (grouped by those that reduce complexity 
and those that increase safety).
The line \emph{Preemptive} represents languages with preemptive 
scheduling~\cite{wsn.mantisos,wsn.tosthreads}, which are summarized further.
The remaining lines enumerate languages with similar goals of \CEU that follow 
a synchronous or cooperative execution semantics (they are sorted by the date 
they first appear in a publication).

Many related works allow events to be handled in sequence through a blocking 
primitive (column \emph{seq}), overcoming the main limitation of event-driven 
systems~\cite{wsn.protothreads, wsn.ocram, wsn.tinythreads, wsn.flowtalk, 
wsn.sol}.
%
Most of them also keep the state of local variables between reactions to the 
environment (column \emph{locals}).
\CEU introduces a reliable mechanism to interface local pointers with the 
system through annotations or finalization blocks (column \emph{final}), as 
discussed in Section~\ref{sec.ceu.fins}.
%
TODO
Regarding compile-time safety guarantees, many related works can provide 
deterministic and reproducible execution relying on cooperative scheduling 
(column \emph{det}).
%
However, as far as we know, \CEU is the first system to extend determinism for 
timers in parallel (as discussed in Section~\ref{sec.ceu.wclocks}).

Synchronous languages first appeared in the context of WSNs through 
OSM~\cite{wsn.osm} and Sol~\cite{wsn.sol}, which provide parallel compositions 
(column \emph{par}) and distinguish from multi-threaded languages by handling 
thread destruction seamlessly~\cite{sync_async.threadsstop,esterel.preemption}.
Compositions are fundamental for the simpler reasoning about control that 
enables the safety analysis of \CEU.
%
Sol detects infinite loops at compile time to ensure that programs are 
responsive~\cite{wsn.sol} (column \emph{bounded}).
\CEU adopts the same policy, which is based on Esterel.
%
Internal events (column \emph{int}) can be used as a reactive alternative to 
shared-memory communication in synchronous languages.
OSM supports a queue-based mechanism based on Esterel~\cite{wsn.osm}, but \CEU 
introduces a stack-based execution that also provides a restricted but safer 
form of subroutines (as discussed in Section~\ref{sec.ceu.ints}).

\emph{nesC} provides a data-race detector for interrupt handlers (column 
\emph{shared}):
\emph{``if a variable x is accessed by asynchronous code, then any access of x 
outside of an atomic statement is a compile-time error''}~\cite{wsn.nesc}.
The analysis of \CEU is targeted at synchronous code and point more precisely 
when accesses can be concurrent, what is only possible given its restricted 
semantics.
Furthermore, \CEU extends the analysis for system calls (\emph{commands} in 
\emph{nesC}) and control conflicts (as discussed in Sections~\ref{sec.ceu.det} 
and \ref{sec.ceu.c}).

On the opposite side of concurrency models when compared to \CEU, languages 
with preemptive scheduling assume time independence among processes and are 
more appropriate for applications involving algorithmic-intensive 
problems.
%
Preemptive scheduling is also employed in real-time operating systems to 
provide response predictability, typically through prioritized schedulers
~\cite{wsn.mantisos,wsn.oses,freertos,wsn.tosthreads}.
%
The choice between the two models should take into account the nature of the 
application and is a trade-off between safe synchronization and predictable 
responsiveness.

\section{Conclusion}
\label{sec.conclusion}

%
%We explore the precious control information that can be inferred from thread
%compositions at compile time in order to embrace safety aspects to a greater 
%extent.
% most safety guarantees actually make the programming experience more 
% expressive

\begin{comment}
Our overall contribution is a careful language design that considers these
mechanisms together in a analysis that can detect safety threats at compile 
time, such as concurrent accesses to shared memory, and concurrent termination 
of timers and threads.
%
%We explore the precious control information that can be inferred from thread
%compositions at compile time in order to embrace safety aspects to a greater 
%extent.
%
CONCLUSION
Note that one of the main objectives of \CEU is to enhance safety in concurrent 
patterns, in the sense that if the programmer sticks to \CEU primitives for 
control patterns it will gain...
avoid cycles
The stack execution policy for internal events can express nested emits, and 
also avoids dependency cycles in programs.

In \CEU, there are three possible sources of non-determinism:
\emph{concurrent access to variables} (e.g. \code{(1=>a\&\&2=>a)}),
\emph{concurrent \emph{par/or} termination} (e.g. \code{(1||2)=>a}, might yield 
$1$ or $2$), and \emph{concurrent loop escape}%
\footnote{ The token \brk{} escapes the innermost loop with its preceding 
expression. }
(e.g. \code{(1\brk{} \&\& 2\brk)* =>a}).

During compile time, \CEU{} converts programs into deterministic finite 
automatons in order to detect the three forms of non-determinism.
This conversion is the reason why \CEU{} is a static language.
% TODO: claim
A DFA unequivocally represents a \CEU{} program, covering exactly all possible 
paths it can reach during runtime.
For instance, the following program is identified as non-deterministic, because 
the variable $v$ is accessed concurrently on the 6th occurrence of the event 
$A$:

\Code{
(\til{}A; \til{}A; 1=>v)*
\&\&
(\til{}A; \til{}A; \til{}A; v)*
}

% BACKGROUND

- hard vs soft real-time

% BENCHMARKS

- TinyOS
    - minimization and prevention [decade]
        - minimizing resource   (constraint)
        - preventing bugs       (constraint)
    - isolation
        - not in protothreads
        - static
        - "it makes each component's interaction to an underlying shared 
          resource completely independent"

    - EFICIENCY: minimization
    - SAFETY: prevention, isolation
    - EXPRESSIVENESS: isolation

- Protothreads
    - state machines removal
    - solves sequential execution
    - subsequent alternatives are similar
    - wide use
    - available
    - represents all alternatives that follows the right approach
        (synchronous concurrency)

    - no isolation

    - EXPRESSIVENESS: state machines
    - SAFETY: ?
    - in terms of safety not many gains, still shared-globals (isolation),

% CONTRIBUTIONS

- thinked together
- both aspects are embraced in a single design:
    - safety is not possible w/o extra information aquired from high-level
    - high-level is not possible w/o safety
    - ex.
        - par/or w/ stacked internal emits for killing
        - par for shared-memory
        - shared-memory analysis is not possible w/o par

% DESIGN

- timers
    - exemplo da chamada periodica a alarme que avoids ""

% EVALUATION

    - we sticked to the component model
        - protothreads rewrote?
        - if we rewrite? (drip gains)

    - lines/tokens

    - states

    - other globals

    - features used in examples: par/or/and, wclocks, OO

    - finally p/ cancelar mensagens (timers, evts, nao precisa)
    - mais uma razao para ter timers de 1a classe (sao cancelados 
      automaticamente)
    - procurar nos exs. do tinyOS por TODOs relacionados a isso

- send é hold
    finally p/ cancelar
- receive é nohold

In the XXX protocol a message to XXX needs is sent whenever XXX.
In the code snippet that follows, the declaration of the messasge buffer is 
local and is N levels of depth to the top-level block of the code.
Hence, much more readable than having a global that you cannot say where it is 
used if not inspecting the whole code.

internal events are needed to eliminate state when they occur in the middle of 
a par trail (i.e., the trail is not signaling with its termination)

However,.

    - isolation
        - eliminated queues and pools
            - full queue is equivalent to miss an event

- CTP exemplo radio? / ctp? (4 estados) transformados em start/stop (que 
  carregam uma semantica) // controle dessas variaveis totalmente localizado em 
paralelo com o programa, sem globais

par/and p/ evitar chamadas que retornam erro:

Timer.periodic(XXX)
Timer.fired() {
    if (call AMSend.send()) {
        ...
    }
}

await XXX;
loop do
    par/and do
        await XXX;
    with
        AMSend.send();
        await SEND\_DONE;
    end
end

-- se ha multiplos:

await XXX;
loop do
    par/and do
        await XXX;
    with
        loop do
            AMSend.send();
            await SEND\_DONE;
            if me then
                break;
            end
        end
    end
end

-- FINALIZE

%find . -name "*.nc" | xargs egrep -R "\.send\(|\.send \(" | grep -v command | 
%wc
%=> 349

%find . -name "*.nc" | xargs egrep -R "\.cancel\(|\.cancel \(" | grep -v 
%command | wc
%=> 49

Bug in SRP:
- usually in TinyOS, decrease in performance, waste of radio, but buffer is 
  global
HOWEVER:
- client takes a message from MessagePool

related: lembrar que PROTO e OCRAM têm sequential composition
    PT\_SPAWN e normal call

\end{comment}

\begin{comment}
Figure~\ref{lst.ctp} shows how we use internal events to abstract the 
start/stop operations for our port of the CTP collection 
protocol~\cite{wsn.teps} to \CEU.

The first column of Figure~\ref{lst.ctp} declares the internal events and 
mimics the start/stop pattern used for the radio driver in 
Figure~\ref{lst.radio}.
In parallel, we define the actual behavior for the operations (expanded in the 
second column), which depend not only from external requests to start/stop the 
protocol but also from the radio status.

The second column keeps track of the current external state through the local 
variables \code{ctp?} and \code{radio?}%
\footnote{\CEU allows the symbol \code{?} in identifiers.}
and emits the appropriate event when TODO, multiplexing four external events 
into two internal events.

\begin{figure}[t]
%\rule{8.5cm}{0.37pt}
\begin{minipage}[t]{0.45\linewidth}
{\small
\begin{verbatim}
event void start;
event void stop;
par do
  // start/stop pattern
  loop do
    await start;
    par/or do
      await stop;
    with
      // executes CTP
      <...>
    end
  end
with
  <code to emit start/stop>
end
\end{verbatim}
}
\end{minipage}
%
\hspace{0.0cm}
%
\begin{minipage}[t]{0.45\linewidth}
%\fbox{
{\small
\begin{verbatim}
// <code to emit start/stop>
var int ctp?   = 0;
var int radio? = 0;
loop do
  par/or do
    await CTP_START;
    ctp? = 1;
  with
    await CTP_STOP;
    ctp? = 0;
  with
    await RADIO_STARTDONE;
    radio? = 1;
  with
    await RADIO_STOPDONE;
    radio? = 0;
  end
  if ctp? and radio? then
    emit start;
  else
    emit stop;
  end
end
\end{verbatim}
%}
}
\end{minipage}
\rule{8.5cm}{0.37pt}
\caption{ Start/stop behavior for the CTP protocol.
\label{lst.ctp}
}
\end{figure}

\begin{minipage}[t]{0.20\linewidth}
{\small
\begin{verbatim}
/* PROTOTHREADS IMPLEMENTATION */
PT_THREAD blink0 (<...>) {
  static struct timer timer;
  PT_BEGIN();
  while (1) {
    timer_set(&timer, 250);
    PT_WAIT_UNTIL(timer_expired(&timer));
    leds_toggle(LEDS_RED);
  }
  PT_END();
}
PT_THREAD blink1 (<...>) {
  static struct timer timer;
  PT_BEGIN();
  while (1) {
    timer_set(&timer, 500);
    PT_WAIT_UNTIL(timer_expired(&timer));
    leds_toggle(LEDS_GREEN);
  }
  PT_END();
}
int main (void) {
  static struct timer timer;
  PT_INIT(&blink0);
  PT_INIT(&blink1);
  timer_set(&timer, 60000);
  while (
    PT_SCHEDULE(blink0()) &&
    PT_SCHEDULE(blink1()) &&
    !timer_expired(timer)
  );
  leds_off(LEDS_ALL);
  <...> // CONTINUE
}

\end{verbatim}
}
\end{minipage}
%
\hspace{0.0cm}
%
\begin{figure*}[t]
%\rule{8.5cm}{0.37pt}
\begin{minipage}[t]{0.22\linewidth}
{\small
\begin{verbatim}
/* NESC IMPLEMENTATION */
event void Boot.booted () {
  call T0.startOneShot(0);
  call T1.startOneShot(0);
  call T2.startOneShot(60000);
}
event void T0.fired () {
  call Leds.led0Toggle();
  call T0.startOneShot(250);
}
event void T1.fired () {
  call Leds.led1Toggle();
  call T0.startOneShot(500);
}
event void T2.fired () {
  call T0.cancel();
  call T1.cancel();
  call Leds.set(0);
  <...> // CONTINUE
}
\end{verbatim}
}
\end{minipage}
%
\hspace{0.0cm}
%
\begin{minipage}[t]{0.20\linewidth}
{\small
\begin{verbatim}
/* MANTISOS IMPLEMENTATION */
static int ended;
void blink0 () {
  uint32_t dt = 250;
  while (!ended) {
    mos_led_toggle(0);
    mos_thread_sleep(dt);
  }
}
void blink1 () {
  uint32_t dt = 500;
  while (!ended) {
    mos_led_toggle(1);
    mos_thread_sleep(dt);
  }
}
void main () {
  ended = 0;
  mos_thread_new(blink0);
  mos_thread_new(blink1);
  mos_thread_sleep(60000);
  ended = 1;
  mos_led_display(0);
  <...> // CONTINUE
}
\end{verbatim}
}
\end{minipage}
%
\hspace{0.0cm}
%
\begin{minipage}[t]{0.20\linewidth}
%\fbox{
{\small
\begin{verbatim}
/* OCRAM IMPLEMENTATION */
static int ended;
THREAD void blink0 () {
  uint32_t now = tc_time();
  while (!ended) {
    tc_toggle_led_0();
    tc_sleep(now+=250);
  }
}
THREAD void blink1() {
  uint32_t now = tc_time();
  while (!ended) {
    tc_toggle_led_1();
    tc_sleep(now+=500);
  }
}
THREAD void main () {
  ended = 0;
  // blink0 auto starts
  // blink1 auto starts
  tc_sleep(tc_time()+60000);
  ended = 1;
  tc_set_leds(0);
  <...> // CONTINUE
}
\end{verbatim}
%}
}
\end{minipage}
%
\hspace{0.0cm}
%
\begin{minipage}[t]{0.18\linewidth}
%\fbox{
{\small
\begin{verbatim}
/* CEU IMPLEMENTATION */
par/or do
   loop do
      _Leds_led0Toggle();
      await 250ms;
   end
with
   loop do
      _Leds_led1Toggle();
      await 500ms;
   end
with
   await 1min;
end
_Leds_set(0);
<...> // CONTINUE
\end{verbatim}
%}
}
\end{minipage}
\rule{18cm}{0.37pt}
\caption{ ``Two blinking LEDs'' in
    nesC~\cite{wsn.nesc},
    MantisOS~\cite{wsn.mantisos},
    Ocram~\cite{wsn.ocram},
    and \CEU.
\label{lst.all}
}
\end{figure*}

\begin{figure}[t]
%\rule{8.5cm}{0.37pt}
\begin{minipage}[t]{0.50\linewidth}
{\small
\begin{verbatim}
 // Ocram implementation
 THREAD void blink1() {
    int now = tc_time();
    while(1) {
       now += 250;
       tc_sleep(now);
       tc_toggle_led_0();
    }
 }
 THREAD void blink2() {
    int now = tc_time();
    while(1) {
       now += 500;
       tc_sleep(now);
       tc_toggle_led_1();
    }
 }
\end{verbatim}
}
\end{minipage}
%
\hspace{0.0cm}
%
\begin{minipage}[t]{0.40\linewidth}
%\fbox{
{\small
\begin{verbatim}
// Ceu implementation
par do
   // blink 1
   loop do
      await 250ms;
      _Leds_led0Toggle();
   end
with
   // blink 2
   loop do
      await 500ms;
      _Leds_led1Toggle();
   end
end
\end{verbatim}
%}
}
\end{minipage}
\rule{8.5cm}{0.37pt}
\caption{ ``Two blinking LEDs'' in Ocram and \CEU.
\label{lst.blink}
}
\end{figure}

Figure~\ref{lst.blink} illustrates this difference, showing the implementations 
for two blinking LEDs with both approaches.

In the Ocram~\cite{wsn.ocram} implementation, the two threads are defined as 
global functions and must be controlled manually, i.e.,
the decision to start or terminate each is independent of one another and up to 
the programmer.

In the \CEU implementation, the two trails are syntactically tied together 
inside a \code{par} composition, implying that
(a) they can only exist together;
(b) they always start together
(c) if they terminate, they do it together.

Besides the arguably cleaner syntax, the additional control-flow information 
provided in the program is the base for all features and safety guarantees 
introduced by \CEU.

The \code{par} composition is used when the trails are intended to run forever, 
but \CEU also provides compositions that logically combine trails:
a \code{par/or}  terminates (rejoins) when any of its trails terminates;
a \code{par/and}, only when all terminate;

Although the two multi-threaded implementations look syntactically the same, 
the underlying execution semantics provided by the languages is fundamentally 
different.

On the one hand, preemptive multi-threading provides better responsiveness for 
time critical applications~\cite{wsn.comparison}.
On the other hand, as exemplified in the example, the inherent 
non-deterministic scheduling demands a larger (and error-prone) effort with 
synchronization issues when compared to the simpler run-to-completion semantics 
of cooperative multi-threading.
In the context of WSNs, the safety aspects have been more critical than 
real-time guarantees, since applications are already built on top of 
unpredictable network links~\cite{wsn.decade}.

The conversion between
straightforward \emph{stubs} that translate a \emph{nesC} event into a \CEU 
input event and that exposes \emph{nesC} commands as $C$ functions.
Figure~\ref{}

{\small
\begin{verbatim}
    #define ceu_out_event_TRICKLE_FIRED(i) \
        signal TrickleTimer.fired[*i]();

    #define Random_rand16() \
        call Random.rand16()

    #include "_ceu_defs.h"
    #include "_ceu_code.cceu"

    command error_t Init.init() {
        ceu_go_init();
        return SUCCESS;
    }

    command error_t TrickleTimer.start[uint8_t id]() {
        ceu_go_event(IN_TRICKLE_START, &id);
        return SUCCESS;
    }

    command void TrickleTimer.stop[uint8_t id]() {
        ceu_go_event(IN_TRICKLE_STOP, &id);
    }
\end{verbatim}
}

In Esterel, time is defined as discrete reaction steps in which multiple 
external signals (events in \CEU) can be queried on their presence status.
This semantics has more proximity with that of electronic circuits, but 
simultaneous events would inhibit the temporal analysis of \CEU.
For instance, variable manipulation in Esterel is restricted to a single 
process (trail in \CEU).

\subsection{Code reentrancy}
\label{sec.ceu.oo}

Applications frequently require multiple instances of an abstraction to coexist 
during runtime.
As an example, to keep track of multiple dissemination values, an application 
may create multiple instances of the DRIP protocol which, in turn, each 
requires a local instance of a trickle timer.

Code reentrancy is a technique to avoid duplicating code to save ROM:
the same code is shared among instances, which only differ on their data and
point of execution.

In traditional multi-threaded systems, code reentrancy is achieved with 
function declarations that are executed with different stacks and instruction 
pointers.
In object oriented languages, a \emph{class} encapsulates methods and 
properties, and can be instantiated as objects.

In \CEU, we designed an hybrid approach, which combines threads and classes in 
the so called \emph{organisms}.
An organism class is composed of an \emph{interface} and a single \emph{body}.
The interface exposes public variables and internal events that other organisms 
(and the top-level body) can refer.
The body of a class is equivalent to a trail, having access to all presented 
functionality provided by \CEU, such as parallel compositions, $C$ calls, 
timers, etc.
An organism is instantiated by declaring a variable of the desired class, and 
its body is automatically spawned in a \code{par/or} with the enclosing block.
A method can be simulated by exposing an internal event in the interface of the 
class and using the same technique of Figure~\ref{lst.func}.

The first column of Figure~\ref{lst.orgs} re-implements the example of 
Figure~\ref{lst.all} to blink two LEDs with different frequencies.
The \code{Blink} class exposes the \code{led} and \code{freq} variables to be 
configured by the application, which then creates two instances and initializes 
them.

The second column shows how the organisms bodies are expanded to run in a 
\code{par/or} together with the enclosing block body.
The expansion is illustrative, i.e., the code is not duplicated.
Note that in the expansion, the bodies of the organisms are followed by 
\code{await~FOREVER}%
\footnote{\code{FOREVER} is a reserved keyword in \CEU, and represents an 
external input event that never occurs.}%
, meaning that only the enclosing block can terminate the \code{par/or}.
Note also that the block body runs first and properly initializes the organisms 
before they are spawned.

Once the enclosing block terminates, declared organisms are killed and all 
memory can be reused, just as happens in standard parallel compositions.
The allocation and deallocation of organisms is static, with no runtime 
overhead such as garbage collection.

\begin{figure}[t]
%\rule{8.5cm}{0.37pt}
\begin{minipage}[t]{0.45\linewidth}
{\small
\begin{verbatim}
C _on(), _off();

class Blink with
   var int led;
   var int freq;
do
   loop do
      _on(this.led);
      await (this.freq)s;
      _off(this.led);
      await (this.freq/2)s;
   end
end

var Blink b1;
b1.led  = 0;
b1.freq = 2;

var Blink b2;
b2.led  = 1;
b2.freq = 4;

await 1min;
\end{verbatim}
}
\end{minipage}
%
\hspace{0.0cm}
%
\begin{minipage}[t]{0.45\linewidth}
%\fbox{
{\small
\begin{verbatim}
C _on(), _off();
var Blink b1, b2;
par/or do
   b1.led  = 0;
   b1.freq = 2;
   b2.led  = 1;
   b2.freq = 4;
   await 1min;
with
   loop do
      _on(b1.led);
      await (b1.freq)s;
      _off(b1.led);
      await (b1.freq/2)s;
   end
   await FOREVER;
with
   loop do
      _on(b2.led);
      await (b2.freq)s;
      _off(b2.led);
      await (b2.freq/2)s;
   end
   await FOREVER;
end
\end{verbatim}
%}
}
\end{minipage}
\rule{8.5cm}{0.37pt}
\caption{ ``Two blinking LEDs'' using organisms.
\label{lst.orgs}
}
\end{figure}

Figure~\ref{lst.srp} shows part of our port of the SRP routing 
protocol~\cite{wsn.teps} to \CEU.
The protocol specifies a fixed number of \emph{forwarders} responsible for 
routing received messages to neighbours based on a static table.
Given that a forwarder holds internal state (i.e. a message buffer and the 
forwarding activity), we define a \code{Forwarder} class and create multiple 
instances to serve requests.

The first column of Figure~\ref{lst.srp} shows the receiving loop of the 
protocol, which invokes \code{emit~go} when a message needs to be forwarded.
The event is declared as global, so that \code{Forwarder} instances have access 
to it.
The forwarders are declared in a vector, creating \code{COUNT} different 
instances.
As the vector is local, all instances are automatically killed when the 
protocol is stopped.
(Note the use of the start/stop pattern of Figure~\ref{lst.radio} again.)

The second column of Figure~\ref{lst.srp} shows the \code{Forwarder} class.
Initially, all forwarders are in the same state, waiting for the global event 
\code{go}.
Once the receiving loop emits the event in the top-level body, the forwarders 
awake in the order they were declared.
The first forwarder atomically sets the \code{gotcha} variable, indicating that 
the message will be handled and that other forwarders should ignore it:
all other forwarders will await again for the next \code{go} emission.
With this technique, we eliminated the need of an explicit queue.
In the case that all forwarders become busy, the \code{go} emission will be 
missed (with \code{gotcha=0}), acting just like a full queue.

%begin{comment}
Note that \CEU organisms are not global entities and do not use the heap for 
memory.
Instead, they are bounded to the scope they are declared, and all memory is 
statically allocated, just like \CEU does for standard local variables.
Also, when an organism goes out of scope, the same automatic bookkeeping of 
\code{par/or} compositions holds, all internal trails are killed and 
finalization blocks execute (if any).
Hence, the ``garbage collection'' for both the memory and code in organisms is 
efficient and static.
Although \CEU does not support dynamic creation (which could lead do unbounded 
memory), scoped organisms offer some degree of flexibility when compared to 
systems providing global objects only~\cite{wsn.virgil,wsn.flowtalk}.
%end{comment}

% TODO: ND access

\begin{figure}[t]
%\rule{8.5cm}{0.37pt}
\begin{minipage}[t]{0.45\linewidth}
{\small
\begin{verbatim}
event _fwd_t go;
loop do
  await SRP_START;
  par/or do
    await SRP_STOP;
  with
    var Forwarder[COUNT] fwds;
    <initialize fwds>
    loop do
      await SRP_RECEIVE;
      <receive or forward>
      if hops_left > 0 then
        <prepare fwd>
        emit go=&fwd;
      end
    end
  end
end
\end{verbatim}
}
\end{minipage}
%
\hspace{0.0cm}
%
\begin{minipage}[t]{0.45\linewidth}
%\fbox{
{\small
\begin{verbatim}
class Forwarder with
  <...>
do
  loop do
    fwd = await global:go;
    if fwd:gotcha then
      continue;
    end
    fwd:gotcha = 1;
    <send message>
    <...>
  end
end
\end{verbatim}
%}
}
\end{minipage}
\rule{8.5cm}{0.37pt}
\caption{ SRP forwarders as organisms.
\label{lst.srp}
}
\end{figure}

%begin{comment}
Objects
    - each method is a global function receiving a different object to 
      manipulate
    - global (usually heap)
    - garbage collected or global

Organisms
    - mutual reactivity
    - scoped / local
    - O(1) GC

- nesting
    - data
    - events
    - listeners
    - compositions

- both have an interface
- fields / methods

- fields / internal events
- public fields are ok because reliable shared memory

- no recursive definitions
- but we have interfaces
- special global interface
%end{comment}

\begin{table}[t]
\begin{center}
\begin{tabular}{ | c || c || c | c || c | c | }
\hline
            & send  & per1 & dur1 &  per2 & dur2  \\ \hline
    Test 1  & 200ms &  5ms & 1ms  &  50ms &  5ms  \\ \hline
    Test 2  & 200ms &  5ms & 2ms  &  50ms & 10ms  \\ \hline
    Test 3  & 200ms & 10ms & 5ms  & 100ms & 50ms  \\ \hline
\hline
    Test 4  & 100ms &  5ms & 1ms  &  50ms &  5ms  \\ \hline
    Test 5  & 100ms &  5ms & 2ms  &  50ms & 10ms  \\ \hline
    Test 6  & 100ms & 10ms & 5ms  & 100ms & 50ms  \\ \hline

\end{tabular}
\caption{Test parameters for the radio performance.}
\label{tab:comparison}
\end{center}
\end{table}

We adjusted the parameters to identify two situations of interest:

\emph{Scenario 1}: the limit in which both implementations receive all messages 
and perform equally in the activities.
\emph{Scenario 2}: the limit in which the \CEU implementation starts to loose 
packets.

Then we ... for more stress test
\emph{Scenario 3}: doubling the sending frequency from the previous scenario
5 motes

Table~\ref{tab.radio} shows the chosen parameters for the three scenarios and 
Figure~\ref{fig.radio1}

As Figure~\ref{fig.radio1} shows, in \emph{Scenario 1} both implementations 
perform equally, without packet losses and completing the activities the same 
number of times.
\emph{Scenario 2}.

\begin{enumerate}
\item send=100ms, act1=75ms/dur1=1ms, act2=180ms/dur2=3ms
\item send=100ms, act1=45ms/dur1=1ms, act2= 90ms/dur2=3ms
\item send= 50ms, act1=45ms/dur1=1ms, act2= 90ms/dur2=3ms
\end{enumerate}

We introduce the term byte time to refer to the duration
that it takes to transmit a single byte of data over the radio.
On the Mica2, a byte time is 0.42 ms.
For the largest possible packet size using TinySec-
AE, a maximum of 10 block cipher operations are required,
hence the block cipher must take no more than 28/10 = 2.8
byte times per operation.
===> 2.8 * 0.42 = 1.176
Cipher \&
Impl.
RC5 (C) Skipjack (C) RC5 (C, assembly)
Time (ms)
0.90    0.38         0.26
Time (byte times)
2.2     0.9          0.6

% TODO
SRP rate
CTP rate:

DRIP sample rate=
    Trickle rate= 1 -> 1024

CTP RT: beacon 128->512k ms
        size=5bytes
CTP FW: 32ms + recv rate
        size=8bytes + data

TestNetwork
        snd interval = 8192

all use random deltas to avoid XXX

As more specific contributions, we enumerate the following features:
\begin{itemize}
\item A compile-time analysis for reliable shared-memory concurrency.
\item A finalization mechanism to safely release resources just before they go 
      out of scope.
\item First-class timers with a predictable behavior.
\item Stack-based inter-thread communication, which provides a restricted (but 
      safer) form of subroutines.
      % and can be used to handle exceptions.
%\item An object system that provides code reentrancy and enables the creation 
%of higher-level abstractions.
\end{itemize}

\CEU is based on Esterel~\cite{esterel.ieee91} and follows a synchronous 
execution model~\cite{rp.twelve}, which enforces a disciplined step-by-step 
execution.
\CEU relies on a compile-time analysis to detect unbounded loops and concurrent 
access to variables.

Our design is first compromised with the main principles that govern WSNs 
development: \emph{resource minimization} and \emph{bug prevention}, as defined 
by Levis~\cite{wsn.decade}.
That said, the support for hierarchical compositions, together with a 
convenient syntax for timers and internal communication also lead to more 
compact programs (up to 70\% reduction, in our evaluation).

TODO

SAFETY, both react to time, what if they access memory, who executes first
CEU detects at compile time and raises a warning

Node-system-imperative
    - not macro
    - not declarative
    - drivers, protocols, control-intensive apps

Synchronous
    - not preemptive, actors

ED->MT->HC

Safety and expressiveness co-design

abstractions need to be first class

However, without architectural changes, we could not express XXX how.
more lines, more ROM
    - not always represent the Céu way
        - full DRIP 40%

and is used  works (e.g. \cite{wsn.protothreads,wsn.sol,wsn.flask}) already 
        include comparisons to nesc, allowing (at least) an indirect comparison 
of \CEU{} with them.

\footnote {
    We used $TinyOS-2.1.1$ and $micaz$ motes, and the sample applications found 
in \code{/opt/tinyos-2.1.1/apps/}.
}

Research in Wireless Sensor Networks continuously pursues ways to reduce 
programming efforts without introducing significant resource overheads.
%Multi-threaded and synchronous languages offer proper support for sequential 
%programming, overcoming the difficulties of (still prevailing) event-driven 
%development.
However, most analysis and mitigation efforts regarding safety threats in 
control and concurrency are still delegated to programmers (e.g.  handling 
synchronization and shared-memory among activities).

We present a system language design that prioritizes safe concurrency and 
enforces handling threats at compile time, rather than providing runtime 
mechanisms only.
%Our design supports concurrent lines of execution that run in time steps and 
%are allowed to share variables.
On the one hand, the synchronous and static foundation of our design imposes 
limitations on its expressiveness, such as for implementing
computation-intensive operations and ensuring hard real-time responsiveness.
On the other hand, the simpler reasoning about concurrency enables a 
compile-time analysis that ensures deterministic and memory-safe programs.
%, even in the presence of pointers and low-level system calls.
%
We show that the achieved expressiveness and responsiveness is sufficient to 
implement a selected number of standardized network protocols and a radio 
driver, reducing considerably the code complexity, and with a increase in 
memory below 10\% in terms of total ROM and RAM.
%(measured in number of tokens)

Control-intensive applications benefit from the former, while
with a low synchronization rate or for those
safe and automatic synchronization at the cost of manually ensuring 
responsiveness;
while XXX benefit from predictable responsiveness at the cost of manual
synchronization.
more from the first option, while computational-intensive applications that 
hardly synchronize
while for computational-intensive which hardly needs synchronization
On the one hand, the default behavior of activities being independent hinders 
the development of highly synchronized applications, requiring manual 
synchronization

%
A possible scenario is to have a high priority thread in \CEU for the overall 
control of the application, which communicates asynchronously via external 
events with low-priority threads that execute heavy tasks.
A similar scenario has already been proposed~\cite{wsn.tosthreads}.

%Even though \CEU ensures bounded execution for reactions, it cannot provide 
%hard real-time guarantees.

Finally, \CEU was designed for control and that analysis that refuses tight 
loops FROM ERROS at compile time (as discussed in Section~\ref{sec.ceu.det}).
above the 8-ms boundary is

% TODO
%Nevertheless, \CEU does not renounce to practical aspects, providing seamless 
%integration with $C$ for low-level manipulation
%
%With a good balance between low-level and high-level functionality, \CEU{} 
%fits the constrained requirements of embedded systems.

FIM:
% results indicate a good design, features "se encaixam", no bloat
%We conclude that local scopes are currently more important as a programming 
%XXX than to actually a mechanism to reuse memory.
%we checked, all in parallel
%Similar results from evaluations in related work~\cite{wsn.ocram,wsn.sol}
% nesC uses less RAM than \emph{all}.

% two apps in sequence

manual verification of timing constraints
in opposition to
manual sync

resource efficiency and
easy of programming
not relevant
if .

% reproducibility, does not depend on the platform

\end{comment}

\section{Acknowledgments}

\balance
%{\footnotesize
\bibliographystyle{abbrv}
\bibliography{other}
%}

\end{document}
